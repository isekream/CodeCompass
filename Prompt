Optimizing Windsurf.ai: A Guide to Pre-Project Configuration and Setup1. Introduction: Harnessing Windsurf.ai for Optimal Project Kick-offsWindsurf.ai, the evolution of Codeium, presents itself not merely as an AI-powered code assistant but as an "agentic IDE" meticulously designed to foster a developer "flow state". This environment facilitates a seamless collaboration between human developers and artificial intelligence, integrating tools like the Windsurf Editor and various plugins to enhance the coding experience. At its core lies the concept of "Flows," defined as the synergy between AI acting as both an independent "Agent" and a collaborative "Copilot". This philosophy distinguishes Windsurf from earlier AI coding tools, which often focused on line-by-line suggestions. Instead, Windsurf aims for its AI to operate in sync with the developer, comprehending intent, tackling complex, multi-step tasks autonomously, while simultaneously offering contextual assistance.The transition from simpler AI assistance to this more sophisticated agentic model underscores the importance of proactive configuration before embarking on a new development project. While basic features like autocomplete are readily available, unlocking Windsurf's full potential—its ability to understand deep codebase context, execute multi-file edits coherently, and adhere to project-specific standards—necessitates deliberate setup. Features such as project-specific rules defined in .windsurfrules, AI memory persistence, and comprehensive codebase indexing are the mechanisms that provide the AI with the necessary guidance. Configuring these elements upfront ensures the AI partner operates effectively from the project's inception, accelerating development timelines while upholding code quality and consistency.1 This initial investment in setup transforms the AI from a simple assistant into a strategic collaborator. Furthermore, Windsurf's positioning for enterprise use, highlighting benefits like reduced onboarding times and enforcement of coding standards, suggests that configuration choices extend beyond individual preference. Implementing shared rules via .windsurfrules or utilizing remote indexing (an Enterprise feature for shared codebase understanding 2) can become strategic tools for team alignment, knowledge dissemination, and maintaining organizational code quality.This report provides a comprehensive guide to achieving the optimal setup for Windsurf.ai prior to initiating any new software development project. It details the essential steps, from installation and initial configuration to advanced context management techniques, focusing particularly on the crucial .windsurfrules file and effective initial prompting strategies within the Windsurf Editor environment. The goal is to equip developers with the knowledge to configure Windsurf proactively, maximizing its capabilities for a more productive and streamlined development workflow from day one.2. Installation and Initial Configuration: Laying the FoundationThe journey towards an optimized Windsurf environment begins with proper installation and initial setup. Windsurf is available for macOS, Windows, and Linux platforms, with specific minimum system requirements detailed on the official download page. For instance, macOS requires OS X Yosemite or later, Linux needs specific glibc versions (e.g., Ubuntu 20.04+), and Windows necessitates Windows 10 (64-bit).The installation process itself is generally straightforward. Upon launching Windsurf for the first time, users encounter an onboarding flow designed to personalize the environment. A key initial choice involves the setup flow: users can opt for a "Start fresh" configuration or import existing settings and extensions from Visual Studio Code (VS Code) or Cursor. Importing settings provides a significant advantage for users transitioning from these editors, allowing them to retain familiar keybindings, themes, and extensions, thereby lowering the migration barrier and preserving established workflows. The onboarding process also prompts users to select preferred keybindings (default VS Code or Vim) and choose an initial editor theme. An optional step allows adding windsurf to the system's PATH, enabling its launch from the command line.Crucially, activating Windsurf's AI capabilities requires user authentication.3 Users must sign up for a free Windsurf account or log into an existing one. This step is mandatory even for accessing the free tier features. The authentication typically involves a browser-based login flow; upon successful login, the user is redirected back to the Windsurf IDE.3 For browser-based IDEs like GitPod or Codespaces, authentication might involve copying an access token. Potential issues, such as browsers blocking links from the IDE, may require browser updates or manual link handling.Following successful authentication, Windsurf automatically initiates the download of a language server.3 This component is essential, acting as the communication bridge between the local IDE and Windsurf's backend APIs, which power the AI features. The download is typically brief, lasting around ten to twenty seconds depending on internet speed, and the IDE remains fully functional during this process.3 Progress is usually indicated by a notification. This reliance on authentication and a language server communicating with external APIs highlights that Windsurf fundamentally depends on cloud-based infrastructure for its AI operations, even when performing tasks like generating embeddings for local indexing.Users should also be aware of how to keep their Windsurf installation up-to-date. Updates can typically be initiated via a "Restart to Update" button in the menu bar, through the profile icon dropdown ("Check for Updates"), or via the Command Palette (Cmd/Ctrl+Shift+P).While this guide primarily focuses on the integrated Windsurf Editor, it's worth noting that Windsurf also offers plugins for popular IDEs like VS Code and JetBrains.3 The setup process for these plugins mirrors the editor's initial steps: installing the plugin from the respective marketplace, authorizing the account, and allowing the language server to download.33. Understanding Core Concepts for Project SetupTo effectively configure Windsurf before starting a project, it is essential to grasp the core concepts that underpin its AI capabilities. These concepts dictate how Windsurf understands code, interacts with the developer, and maintains context over time.Context Awareness: The Engine of WindsurfAt the heart of Windsurf lies its sophisticated context awareness. Unlike simpler tools that might only consider currently open files, Windsurf strives to comprehend the entirety of a project's repository. This deep understanding is the foundation for generating highly relevant code suggestions, enabling coherent multi-file edits, and powering natural language search queries about the codebase (e.g., "Where do we handle user authentication?"). The system allows users to see which parts of the code were used as context for AI responses, enabling better prompt tailoring.Local Indexing: Building Codebase UnderstandingLocal indexing is the mechanism by which Windsurf builds its comprehensive understanding of the project's codebase.2 It operates by analyzing files across the entire repository—not just those recently accessed—and generating embeddings. These embeddings are numerical representations that capture the semantic meaning of the code, allowing the AI to find relevant context even based on natural language queries or related code snippets. This process significantly enhances the quality of both autocomplete suggestions and chat responses provided by the AI.2 While snippets of code are sent to a remote server to generate these embeddings, Windsurf states that neither the code nor the embeddings are stored remotely; all indexed data resides on the user's local machine. Local indexing is enabled by default within the Windsurf Editor.Cascade: The Agentic CollaboratorCascade is the primary interface for interacting with Windsurf's AI. It functions as more than just a chat window; it's an agentic collaborator capable of generating code, performing complex multi-file edits, suggesting and executing terminal commands, detecting issues, and assisting with debugging. Cascade operates with full contextual awareness of the codebase and can utilize various tools, including codebase search, web search (@web, @docs commands, or automatic detection), integration with custom tools via the Model Context Protocol (MCP), and direct interaction with the integrated terminal. It's designed to maintain a conversational flow, even picking up tasks where the developer left off. Its flexibility is further demonstrated by different operational modes (like Write, Chat, and Legacy) catering to varying levels of automation and interaction desired by the user.Memories & Rules: Persisting GuidanceGiven the complexity of software projects and the need for consistent AI behavior, mechanisms are required to provide persistent, project-specific guidance beyond the scope of a single prompt. Windsurf offers two primary systems for this: Memories and Rules.
Memories: These are pieces of context that Cascade automatically identifies and stores during a conversation if it deems them potentially useful for future interactions within that specific workspace session.4 For example, if Cascade makes a mistake and the user corrects it, Cascade might create a memory of the correction to avoid repeating the error later in the session. These auto-generated memories are dynamic, workspace-specific, and do not persist across different projects or sessions. Users can also explicitly ask Cascade to create a memory.
Rules (.windsurfrules, global_rules.md): In contrast to automatic Memories, Rules are explicitly defined by the user and provide persistent instructions that Cascade endeavors to follow consistently.1 These rules can be defined globally (in global_rules.md, applying to all projects) or, more importantly for pre-project setup, locally within a specific project (via a .windsurfrules file in the project root). The .windsurfrules file is the key mechanism for encoding project-specific coding standards, architectural patterns, and style guides that the AI should adhere to throughout the project's lifecycle.
The distinction between session-based, often automatically generated Memories and user-defined, persistent Rules creates a layered system for managing AI context. Effectively utilizing Windsurf involves understanding when to rely on the AI's adaptive short-term memory and when to enforce fundamental, long-term constraints through explicitly defined rules. This strategic guidance is a core aspect of the pre-project setup process. Consequently, the developer's role subtly shifts; while less time might be spent on writing boilerplate code, more effort is directed towards effectively guiding the AI through meticulous context configuration via indexing settings and rule definition.4. Deep Dive: Configuring Your Project EnvironmentWith a grasp of the core concepts, the next step is to delve into the specific configuration options that allow for tailoring Windsurf to a particular project's needs before coding commences. This involves mastering rule definition, optimizing codebase indexing, and understanding other relevant settings.4.1. Mastering .windsurfrulesThe .windsurfrules file is arguably the most critical configuration element for pre-project setup. It serves as the primary mechanism for providing persistent, project-specific instructions to Cascade, ensuring the AI's behavior aligns with the unique requirements and conventions of the codebase.1Purpose and Location:Placed in the root directory of the project, this file allows developers to encode coding standards, preferred architectural patterns, technology-specific guidelines, required command usage, and other project constraints directly into the AI's operational context.Syntax and Formatting Best Practices:Windsurf processes .windsurfrules as plain text or Markdown. To maximize effectiveness, several best practices should be followed:
Clarity and Conciseness: Rules should be simple, specific, and clearly articulated. Vague or overly long instructions can confuse the AI.
Structure: Use formatting like bullet points, numbered lists, and Markdown headings to organize rules logically. Avoid large, undifferentiated paragraphs.
Specificity: Focus on concrete instructions rather than generic advice (e.g., prefer "Use assign_prop/3 for Inertia props" over "Write good controller code"). Windsurf's base models already incorporate general best practices.
Grouping: XML-style tags can be used to group related rules, enhancing readability for both humans and the AI.
Persona Setting: Starting the file with a statement defining the AI's expected expertise (e.g., "You are an expert in Python, Django, and React") can help set the stage.1
The structure and intent are similar to the .cursorrules file used by the Cursor editor.
Example Analysis (Elixir/Phoenix + Inertia):The following example, extracted from available resources 1, demonstrates the power and specificity of .windsurfrules for a project using Elixir, Phoenix, Inertia, React, and Tailwind CSS:You are an expert in Elixir, Phoenix, PostgreSQL, JavaScript, TypeScript, React, Inertia, and Tailwind CSS.#...source them.This example effectively guides the AI by:
Setting Expertise: Establishing the required knowledge base.
Enforcing Framework Conventions: Specifying exact function calls (assign_prop/3, render_inertia/2), testing helpers (inertia_component/1), migration commands (mix ecto.gen.migration), and module/schema naming conventions crucial for Phoenix and Inertia integration.
Dictating Code Style: Preferring keyword-based Ecto queries over pipe-based ones.
Defining Project Structure: Specifying directory locations for React pages, components, utils, and types, along with export conventions (default vs. named).
Guiding Frontend Practices: Mandating the use of Inertia's useForm hook, absolute imports, a specific utility (cn) for Tailwind class merging, preferred import styles for libraries (Radix), emphasizing responsive design (mobile + desktop), specifying an icon library (lucide-react), enforcing file naming (kebab-case), and preferring TypeScript type over interface.
Providing Tooling/Debugging Instructions: Giving specific psql commands for database debugging and instructing the use of mix check and mix format for code quality and formatting.
Encouraging Collaboration: Asking the AI to seek clarification and suggest improvements.
Adapting for Other Stacks:Developers should adapt these principles to their project's specific stack and team conventions. Consider adding rules for:
Framework patterns (e.g., Next.js routing, middleware usage).
API design standards (e.g., RESTful conventions, GraphQL schema guidelines).
State management library usage (e.g., Redux toolkit patterns, Zustand store structure).
Testing approaches (e.g., preferred Jest/Vitest matchers, testing-library query usage).
Directory organization conventions.
Variable and function naming conventions.
Mandatory linter/formatter commands (e.g., eslint --fix, prettier --write).
Version Control:It is generally recommended to commit .windsurfrules to version control so the entire team benefits from consistent AI guidance. However, if the file contains sensitive paths or highly personalized instructions, adding it to .gitignore might be necessary.Finding More Examples:Windsurf provides curated rule templates in its official directory. Additionally, open-source repositories focused on AI prompts, such as instructa/ai-prompts, can offer inspiration, although they might primarily feature .cursorrules. The underlying principles of providing clear, specific, and structured guidance remain the same.Crafting a detailed and effective .windsurfrules file is akin to creating a foundational "system prompt" for the entire project. It represents a significant part of the "configuration engineering" effort required to optimize Windsurf, directly influencing the quality, consistency, and relevance of all subsequent AI interactions.4.2. Optimizing Codebase IndexingWhile local indexing operates automatically in the Windsurf Editor, optimizing its configuration is crucial for ensuring the AI has access to the right context without impacting performance, especially in large repositories.Controlling Indexed Content:Windsurf employs a hierarchical approach to determine which files are indexed:
.gitignore: Files and patterns listed in the project's .gitignore file are automatically excluded from indexing by default. This is the first line of defense against indexing irrelevant build artifacts, dependencies, and environment files. Maintaining a comprehensive .gitignore is essential.
Default Ignores: Windsurf also ignores node_modules directories and hidden files/directories (those starting with a ".") by default.
.codeiumignore: For more granular control beyond .gitignore and defaults, developers can create a .codeiumignore file in the project root.2 This file uses the same syntax as .gitignore and allows specifying additional patterns to exclude. Common use cases include ignoring large data files, specific test suites, generated code not covered by .gitignore, or sections of legacy code that shouldn't influence current AI suggestions.
Strategically using these layers—relying on .gitignore for standard exclusions, leveraging defaults for common cases like node_modules, and using .codeiumignore for Windsurf-specific fine-tuning—allows developers to strike a balance. The goal is to provide the AI with comprehensive access to relevant source code while excluding noise and potentially large, irrelevant files that could slow down indexing or skew context retrieval.2Toggling and Performance Considerations:Indexing can be toggled on or off within the IDE settings (specific steps vary slightly between VS Code and JetBrains plugins). More importantly, users can configure the Max Workspace Size (File Count) setting. This determines the maximum number of files in a workspace for which Windsurf will attempt indexing. If a project exceeds this limit, indexing may not occur. Adjusting this value higher might be necessary for large projects, but requires consideration of system resources. The initial indexing process consumes CPU resources and RAM (estimated ~300MB RAM for a 5000-file workspace). While CPU usage returns to normal after the initial index, RAM usage persists. Windsurf documentation recommends setting the file count limit no higher than 10,000 for systems with around 10GB of RAM to avoid performance issues. Users can verify if a workspace is successfully indexed by checking for a green dot next to the workspace name in the "Context" pane of the Chat/Cascade panel.Remote Indexing (Enterprise):For teams using Windsurf Enterprise, remote indexing offers the capability to index repositories stored on platforms like GitHub, GitLab, or BitBucket, even if they aren't checked out locally.2 This facilitates shared codebase understanding across the team. Security measures are in place, such as storing only embeddings (not source code) remotely, using isolated tenant instances, and deleting code snippets after embedding generation.24.3. Leveraging Memories and Global RulesBeyond project-specific .windsurfrules, Windsurf offers other mechanisms for context persistence and guidance.Managing Auto-Generated Memories:As Cascade interacts with the user and the codebase, it may automatically generate "Memories" – short-term, workspace-specific pieces of context it believes are important. Users can view these memories (via the book icon in the Cascade panel or through settings) and can also explicitly ask Cascade to create one (e.g., "Remember that function X should always return a Promise"). While not directly editable like rules, understanding that Cascade builds this dynamic, session-based context is helpful. These memories do not persist across different workspaces or IDE restarts.Global Rules (global_rules.md):For instructions that should apply universally across all projects and workspaces, users can define rules in the global_rules.md file. This file resides in the Windsurf configuration directory and follows the same formatting best practices as .windsurfrules. Use cases include enforcing personal coding style preferences, defining standard aliases for common commands, or providing general instructions not tied to any specific project's technology stack.Persistence Clarification:It is crucial to remember the distinction: Rules (both global and local .windsurfrules) are persistent across sessions and provide stable, long-term guidance. Auto-generated Memories are transient, adapting within a single workspace session. This distinction guides their appropriate use: Rules for foundational standards, Memories for dynamic, short-term conversational context.4.4. Other Key Settings for Pre-Project SetupSeveral other settings within Windsurf can be configured before starting a project to optimize the environment:
AI Model Selection: Paid Windsurf plans offer access to various underlying Large Language Models (LLMs), such as OpenAI's GPT-4 models and Anthropic's Claude models (including Claude 3.5 Sonnet, which can process images), alongside others like DeepSeek and Gemini. Free plans typically provide access to a capable base model and limited credits for premium models. Users with access may want to experiment or select a preferred model based on perceived strengths for specific tasks (e.g., one resource suggests Claude 3.5 excels at code generation with long context). Finding the optimal model might require some initial trial and error.
Feature Toggles: Windsurf's settings allow toggling core features like Autocomplete and the more advanced Supercomplete (which analyzes intent beyond simple completion) on or off. Users can also adjust the autocomplete speed and enable/disable "Clipboard Context," which allows Windsurf to consider recently copied text when generating suggestions. Configuring these based on personal preference can improve the flow state.
Web and Docs Search: Cascade's ability to search the web (@web) or specific documentation sites (@docs), or ingest content from pasted URLs, can be enabled or disabled in the settings. Depending on the project's reliance on external libraries or up-to-the-minute information, users might want to enable these tools from the start. Note that using web search consumes Flow Action credits.
Cascade Terminal Permissions: For users on premium plans, Windsurf allows configuring automatic execution permissions for terminal commands suggested by Cascade. An "allow list" specifies commands that always auto-execute, while a "deny list" specifies commands that never do. For commands not on either list, Cascade uses its judgment (with auto-execution enabled) or prompts the user. Setting up allow lists for frequently used, safe commands (e.g., git status, npm install) can significantly streamline workflows involving command-line operations initiated via Cascade.
The availability of different LLMs and fine-grained controls like terminal permissions offers significant customization but also introduces a layer of complexity. Achieving the truly "perfect" setup might involve some experimentation during the initial phases of a project to fine-tune the AI's behavior and align it with the developer's workflow and risk tolerance.To provide a clearer overview of the various ways Windsurf manages context, the following table summarizes the key mechanisms:
MechanismScopePersistenceControlPrimary Use CaseRelevant SourcesLocal IndexingEntire Local WorkspacePersistent (Local)ConfigurableBase codebase understanding for chat/autocomplete2Remote Indexing (Ent.)Specified Remote ReposPersistent (Remote)ConfigurableShared team codebase understanding2Auto-Generated MemoriesCurrent WorkspaceSession-BasedAutomatic (View)Dynamic, short-term conversational context adaptation.windsurfrulesProject (Local Root)PersistentUser-DefinedEnforcing project-specific standards, patterns, conventions1global_rules.mdAll WorkspacesPersistentUser-DefinedEnforcing personal preferences, global tool usageContext PinningSpecific Files/DirsPersistentUser-DefinedEnsuring specific critical context is always considered@mentionsSpecific Files/FunctionsPrompt-BasedUser-DefinedExplicitly bringing specific code items into the current prompt's contextClipboard ContextLast Copied TextTransientSetting ToggleAllowing AI to consider clipboard content for suggestionsHighlighted Code ContextSelected Code SnippetPrompt-BasedUser ActionDirectly referencing selected code in Cascade chat or inline commandsURL Input / @web / @docsExternal Web ContentPrompt-BasedUser ActionBringing external documentation, articles, or live web search results into context
Understanding these different layers and their characteristics is fundamental to strategically managing context and effectively guiding Windsurf's AI.5. Pre-Project Setup ChecklistTo ensure a smooth and optimized start with Windsurf for any new project, follow this practical checklist summarizing the key configuration steps to perform before writing significant project code.
StepActionKey Settings/FilesRelevant SourcesNotes1. Install/UpdateEnsure the latest version of the Windsurf Editor is installed.Windsurf ApplicationCheck for updates via Profile icon or Command Palette.2. AuthenticateLog in to your Windsurf account.Windsurf Account CredentialsMandatory for enabling AI features.3. Open ProjectOpen the root directory of your new or existing project within the Windsurf Editor.File > Open Folder...Establishes the workspace context.4. Initial Settings(Optional) Import settings/extensions from VS Code/Cursor if desired. Choose editor theme and keybindings. Select preferred AI Model (paid plans). Adjust feature toggles (autocomplete, etc.). Configure terminal command permissions.Settings UI, Command PaletteTailor the basic IDE experience and AI behavior to preferences.5. Configure IndexingVerify local indexing is enabled. Review/adjust Max Workspace Size (File Count). Review project .gitignore. Create/update .codeiumignore file. Allow initial indexing time.Settings UI, .gitignore, .codeiumignore2Ensures AI understands the relevant codebase efficiently. .codeiumignore uses .gitignore syntax for Windsurf-specific ignores.6. Define Project RulesCreate/edit the .windsurfrules file in the project root. Add rules for project standards, tech stack conventions, patterns, commands, etc. Format clearly..windsurfrules (Project Root)1The core of project-specific AI guidance. Commit to version control for team consistency unless sensitive.7. Define Global Rules(Optional) Add/update personal, non-project-specific preferences or instructions in the global rules file.global_rules.md (Windsurf Config Dir)For rules applicable across all projects.8. Review Memories(Optional) Check existing auto-generated memories for the workspace (via book icon in Cascade) if resuming work. Consider clearing if starting conceptually fresh.Cascade Panel (Book Icon)Understand the AI's current short-term context.9. Consider Context Pinning(Optional) Identify key files/directories consistently relevant to the project's core logic and consider pinning them for persistent context focus.Context Pane (Right-click)Useful for keeping critical modules always readily available to the AI.
Completing these steps methodically provides a robust foundation, ensuring that Windsurf's AI is properly configured and contextually aware before the main development effort begins.6. Effective Prompting from Day One: Instructing Your AI CollaboratorOnce the Windsurf environment is configured, the focus shifts to interaction. The initial prompts given to Cascade play a crucial role in setting the direction for the project and leveraging the preparatory setup work. Effective prompting assumes that Cascade is now operating with awareness of the indexed codebase, the defined .windsurfrules, and any global rules.Prompting Strategies for Initial Tasks:
Specificity and Clarity: Vague requests yield vague results. Clearly articulate the desired outcome and constraints. Instead of "Set up the project," a more effective prompt would be: "Create the basic directory structure for a Next.js project following the conventions defined in .windsurfrules, including folders for components, pages/api, lib, and styles." This leverages the pre-defined rules and provides concrete deliverables. Good naming conventions in the existing code also help the AI infer context automatically.
High-Level Context: Briefly explain the overall goal of the project or the specific feature being initiated. This helps the AI understand the 'why' behind the request, leading to more relevant suggestions. For example: "This project is an e-commerce backend. Start by setting up the database schema for products."
Explicit Rule Reference: While Cascade should implicitly follow rules, explicitly referencing them can reinforce their application, especially for critical constraints: "Generate a React component for the user profile card, ensuring it adheres to the styling and import rules specified in .windsurfrules."
Leverage Context Tools: Don't rely solely on implicit indexing. Use Windsurf's context tools actively:

Mention specific files, classes, or functions using the @ symbol to bring them into the immediate context.
Paste URLs to documentation pages or relevant articles, or use @docs/@web commands, to provide external context.
Upload images (e.g., Figma designs) to guide UI generation.


Iterative Refinement: Cascade is designed for collaboration, not single-shot generation. Start with broader tasks and progressively refine them. Engage with Cascade's follow-up questions and suggestions. Deliberately review and accept or reject proposed file edits and terminal command executions. If Cascade seems lost, simply prompting "continue" can often resume a multi-step process.
Task Decomposition: Avoid overwhelming the AI with overly complex, monolithic requests. Break down large tasks (like building an entire application) into smaller, logical steps: scaffold structure, define data models, implement API endpoints, create UI components, write tests.
Example Initial Prompts:These examples illustrate how to apply the strategies, assuming relevant .windsurfrules and indexing are in place:
Project Scaffolding: "Based on the tech stack defined in .windsurfrules (e.g., Python, FastAPI, PostgreSQL), generate the initial project structure. Include standard directories like app, tests, scripts, and essential configuration files (pyproject.toml, Dockerfile, .env.example). Ensure pyproject.toml includes basic dependencies for FastAPI and psycopg2."
Database Schema (using Elixir/Phoenix example rules): "Generate an Ecto migration using mix ecto.gen.migration create_products_table and the corresponding schema module (MyApp.Catalog.Product as per plural context/singular schema rules). The 'products' table needs fields: name (string), description (text), price (decimal, precision 10, scale 2), sku (string, unique index).".1
Basic API Endpoint (Node.js/Express): "Create an Express.js router file at src/routes/products.js. Define a GET /api/products endpoint that retrieves all products using a Mongoose ProductModel (assume it exists). Implement basic error handling and structure the JSON response according to the API guidelines in .windsurfrules."
Component from Design: (After uploading dashboard-widget.png) "Generate the Vue.js component code (template and script setup with TypeScript, using Tailwind CSS classes as specified in .windsurfrules) for the UI element depicted in the uploaded image dashboard-widget.png."
Review and Feedback:Critically review all code generated by Cascade, even if it appears correct initially. Use the revert functionality (Cmd/Ctrl+Z or UI buttons) if Cascade makes incorrect changes or goes down the wrong path. Providing corrective feedback ("That's not quite right, the function should handle null inputs like this...") can help Cascade learn within the session (potentially creating Memories) and improve subsequent suggestions.Effective prompting in Windsurf, therefore, transcends simply asking for code; it involves strategically directing the AI by leveraging the carefully configured context established during setup. It's a dialogue where the initial prompt sets the direction, but active user participation—guiding, correcting, and refining—is essential for achieving optimal results, especially in the early stages of a project.7. Conclusion: Maintaining an Optimized WorkflowInvesting time in the pre-project setup of Windsurf.ai—meticulously configuring indexing, defining project standards in .windsurfrules, selecting appropriate settings, and understanding core concepts like Cascade and Memories—establishes a crucial foundation. This upfront effort ensures that the AI collaborator begins the project with the necessary context and guidance, paving the way for a more efficient, consistent, and productive development lifecycle.However, achieving an optimized workflow is not a one-time task. Maintaining the effectiveness of Windsurf requires ongoing attention as the project evolves:
Evolving Rules: As coding standards mature, new libraries are adopted, or architectural patterns shift, the .windsurfrules file must be updated accordingly. Keeping these rules synchronized with the project's reality is vital for continued accurate AI guidance.
Indexing Health: Regularly review and update .gitignore and .codeiumignore to reflect changes in project structure or dependencies. While Windsurf likely handles incremental indexing, significant refactoring might warrant ensuring the index accurately represents the current state.
Continuous Learning and Adaptation: The field of AI coding assistants is rapidly evolving. Developers should stay informed about new Windsurf features and updates by monitoring changelogs. Experimenting with different prompting techniques, exploring advanced features like MCP server integrations for connecting custom tools or databases, and leveraging the broader IDE ecosystem—including integrated previews, deployment capabilities, codelenses for quick actions, and debugging tools—is key to maximizing value.
Sustained Critical Review: The importance of critically reviewing AI-generated code cannot be overstated. Developers must maintain ownership and accountability, treating AI suggestions as proposals rather than infallible directives. Blind trust can lead to subtle bugs or architectural inconsistencies.
Ultimately, Windsurf.ai, when configured thoughtfully and guided effectively, acts as a powerful force multiplier for software development. It automates tedious tasks, accelerates implementation, and helps maintain consistency, freeing developers to focus on higher-level problem-solving, design, and innovation. The initial investment in setup and the ongoing commitment to maintaining that configuration and critically engaging with the AI are essential for realizing these benefits throughout the project lifecycle. The goal is not to replace the developer but to augment their capabilities through intelligent, context-aware collaboration.

Leveraging Starter Repositories and .windsurfrules for Optimal AI-Assisted Development in Windsurf1. Introduction: Enhancing AI Code Generation with Context and RulesWindsurf (formerly Codeium) represents a significant step forward in AI-assisted software development, moving beyond simple code completion towards an agentic IDE capable of understanding complex codebases and collaborating with developers in real-time.1 Central to Windsurf's power is its deep context awareness, achieved through local and remote project indexing.3 This indexing allows Windsurf features like Cascade (its advanced chat and agentic interface) and Windsurf Tab (its enhanced code suggestion system) to provide relevant, multi-file assistance tailored to the specific project.2However, maximizing the effectiveness of AI code generation requires more than just broad context; it necessitates specific guidance on project standards, architectural patterns, and coding conventions. This is where starter repositories and Windsurf's .windsurfrules feature intersect powerfully. Starter repositories (often found on platforms like GitHub) provide pre-configured project structures, dependencies, build tools, linters, formatters, and testing frameworks, embodying best practices for a given technology stack.8The .windsurfrules file allows developers to provide persistent, project-specific instructions directly to the Windsurf AI, guiding its behavior and code generation.11 By creating .windsurfrules that align with the conventions established in a chosen starter repository, developers can ensure the AI generates code that is not only functional but also consistent, maintainable, and adheres to the project's established quality standards. This report explores how to effectively utilize popular starter repositories for common technology stacks (Next.js, Django, Spring Boot) and formulate corresponding .windsurfrules to optimize the AI-assisted development workflow within Windsurf.2. The .windsurfrules Feature: Configuration and Best PracticesThe .windsurfrules file is a key mechanism for customizing Windsurf's AI behavior on a per-project basis, acting as a persistent set of instructions or a style guide for the AI assistant.112.1 Purpose and FunctionalityUnlike temporary instructions given in a chat prompt, .windsurfrules provide enduring guidance that Windsurf's Cascade agent consults whenever generating or modifying code within that specific project.11 These rules complement Windsurf's automatically generated "Memories," which capture context learned during conversations but might be session-specific or less explicit.11 Rules, being user-defined and persistent, offer a more direct and controllable way to enforce project standards, preferred coding patterns, technology usage, and even interaction styles with the AI.11 They function similarly to system prompts in other AI models or the .cursorrules file in the Cursor editor.112.2 Relationship with Other Windsurf Context SourcesWindsurf builds its understanding from multiple sources:
Indexed Codebase (Local/Remote): Provides deep semantic understanding of the entire project's structure and code.3
Open Files/Editor Context: Current code being worked on.
Chat History/Prompt Instructions: Explicit user commands and context provided in the Cascade panel.3
Memories (Automatic/User-Generated): Contextual information remembered by Cascade across interactions.2
.windsurfrules: Persistent, user-defined rules for the specific project.11
The .windsurfrules augment these other sources by providing explicit, unchanging guidelines that the AI should prioritize when generating code or suggestions for that repository.2.3 Configuration and SyntaxConfiguring rules involves creating a simple text file:
File Location: The file must be named .windsurfrules and placed in the root directory of the project repository.11
Syntax: The file uses a straightforward, human-readable format, typically employing Markdown-like syntax. Rules are often defined using bullet points (-) or numbered lists under descriptive headings (e.g., # Elixir and Phoenix Usage).11 XML tags can also be used to group related rules.13
.gitignore Consideration: If the .windsurfrules file contains project-specific, sensitive, or proprietary logic not intended for public sharing (e.g., internal API usage patterns), it is advisable to add .windsurfrules to the project's .gitignore file.13 Otherwise, committing the file ensures the entire team benefits from the same AI guidance.
2.4 Best Practices for Writing RulesTo ensure .windsurfrules are effective, follow these best practices 11:
Be Specific and Explicit: Avoid vague instructions. Clearly state the desired pattern, library, function, or convention.
Be Concise: Keep rules brief and to the point. Overly long or complex rules may confuse the AI.
Use Formatting: Employ bullet points, numbered lists, and Markdown formatting to structure rules logically, making them easier for the AI to parse and follow compared to long paragraphs.
Group Related Rules: Use headings or XML tags to group rules related to a specific language, framework, or concept.
Avoid Generic Instructions: Do not include rules for things already ingrained in large language models, such as "write good code" or "avoid bugs." Focus on project-specific requirements.
Include Interaction Guidelines: Instruct the AI on how to interact, such as asking for clarification if a request is unclear or suggesting alternative approaches.
Leverage Templates: Use existing rule templates as a starting point. Windsurf provides curated examples at https://windsurf.com/editor/directory.13
Consider Indexing: Be mindful of what code is indexed by Windsurf. Rules referencing concepts or code outside the index might require additional context in prompts.
Table: .windsurfrules Best Practices Checklist
Best PracticeDescriptionRationale/BenefitRelevant SourcesBe SpecificClearly define the expected behavior, library, or pattern.Reduces ambiguity for the AI, leading to more accurate results.11Be ConciseKeep rules brief and focused.Improves AI comprehension and avoids overwhelming the model.13Use Markdown FormattingEmploy bullet points, numbered lists, headings.Enhances readability for both humans and the AI parser.11Group Related Rules (XML Tags)Organize rules logically under relevant sections or using XML tags.Improves organization and helps the AI apply rules contextually.13Avoid Generic InstructionsDon't state obvious or universally accepted principles (e.g., "write efficient code").Focuses AI attention on project-specific, actionable guidance.13Include Interaction GuidelinesInstruct the AI on how to handle ambiguity or propose alternatives.Fosters a more collaborative and effective interaction model.11Use TemplatesStart with curated rule templates from Windsurf's directory.Provides a solid foundation and saves time compared to starting from scratch.13Consider IndexingBe aware of which parts of the codebase are indexed and accessible to the AI.Ensures rules are based on context the AI actually possesses.3Add to .gitignore (Optional)Add .windsurfrules to .gitignore if it contains sensitive or proprietary information.Prevents accidental exposure of internal conventions in public repositories.13
2.5 The Rule-Context DependencyA critical consideration when crafting .windsurfrules is the interplay between the rules themselves and the context available to the AI through project indexing.3 Windsurf's ability to understand the codebase relies heavily on the embeddings generated during indexing.3 Rules referencing concepts, files, or code elements not included in this index—perhaps because they are excluded via .gitignore or the .codeiumignore file (which functions similarly to .gitignore for finer control over indexing 3)—may not be applied effectively or accurately. The AI simply lacks the necessary information within its primary context source to follow the instruction correctly.This implies that developers writing .windsurfrules must be mindful of what Windsurf knows based on its indexed context. If a rule pertains to code that is intentionally ignored (like build artifacts or large vendor directories 3) or relates to external systems (like specific database schema details not fully represented in indexed ORM code, or complex third-party API behaviors), the AI might struggle. To mitigate this, developers may need to adjust their ignore files, provide supplementary context directly within prompts when asking for related code generation 14, or leverage future Windsurf capabilities like Model Context Protocol (MCP) servers which can potentially provide access to external tools and information.23. General Best Practices for .windsurfrules (Cross-Stack)While stack-specific rules are crucial, several general best practices apply across different technologies when formulating .windsurfrules. These focus on enforcing consistency in code style, quality, naming, testing, and documentation.3.1 Enforcing Code Style and FormattingMaintaining a consistent code style is vital for readability and collaboration. .windsurfrules can explicitly instruct the AI to adhere to the project's chosen formatter and style guide.
Rule Examples:

Format all generated Python code using Black.
Format all generated JavaScript/TypeScript code using Prettier.
Follow formatting rules defined in.prettierrc.js. 17
Adhere to Python style defined by pyproject.toml [tool.ruff.format] or [tool.black] section. 19
Use single quotes for strings in JavaScript. 17
Limit Python line length to 88 characters. 19


These rules ensure that AI-generated code seamlessly integrates with the existing codebase's style, minimizing the need for manual reformatting.3.2 Promoting Code Quality with LintersLinters analyze code for potential errors, bugs, stylistic issues, and anti-patterns. Rules can guide the AI to produce code compliant with the project's linting setup.
Rule Examples:

Write JavaScript/TypeScript code that passes ESLint checks based on.eslintrc.json. 8
Write Python code compliant with Ruff rules defined in pyproject.toml. 19
Write Python code compliant with Flake8 rules defined in.flake8. 10
Avoid unused variables and imports in generated code. 20
Ensure proper error handling (e.g., avoid bare 'except:' in Python, catch specific exceptions). 24
Follow accessibility guidelines (jsx-a11y) when generating React components. 23


Windsurf's Cascade feature may also offer automatic fixing of lint errors it introduces.2 Rules can reinforce this behavior or specify adherence to particular linter configurations not automatically handled.3.3 Guiding Naming ConventionsConsistent naming conventions significantly improve code readability.
Rule Examples:

Use camelCase for variables and functions in JavaScript, TypeScript, and Java. 27
Use snake_case for variables and functions in Python. 28
Use PascalCase for class names in all languages. 27
Use kebab-case for frontend file names (React components, CSS modules, etc.). 11
All names (variables, functions, classes) must be meaningful and descriptive. 28


3.4 Encouraging TestingTesting is fundamental to robust software development. Rules can prompt the AI to generate tests alongside application code.
Rule Examples:

When creating a new API endpoint, also generate corresponding unit tests using pytest.
Always create tests for new service layer logic in Spring Boot using JUnit 5 and Mockito.
Use pytest fixtures defined in conftest.py for setting up test data. 31
Use @MockBean for mocking Spring dependencies in integration tests (@SpringBootTest). 33
Use @testing-library/react and Jest for testing React components, focusing on user interactions. 8
Generate test files (e.g., *.test.tsx, test_*.py) alongside the component or module being tested. 8


These rules help ensure that testing becomes an integral part of the development process, facilitated by the AI.3.5 Standardizing Documentation CommentsClear documentation is essential for maintainability. Rules can enforce the use of standard documentation formats and required elements.
Rule Examples:

All public functions and methods must have JSDoc comments. 37
All public Python functions, classes, and methods must have Google-style docstrings. 40
All public Java classes, methods, and constructors must have Javadoc comments. 27
Include parameter descriptions (@param / Args:) and return value descriptions (@returns / Returns:) in all function/method documentation. 37
Document thrown exceptions using @throws or @exception. 37


Table: Common Documentation Tags (JSDoc/Javadoc/Docstring)TagLanguage(s)PurposeExample Syntax (Illustrative)@param/Args:JS, Java, PythonDescribes a function/method parameter.@param {string} name - The user's name.@returns/Returns:JS, Java, PythonDescribes the return value.@returns {number} The calculated age.@throws/@exceptionJS, Java, PythonDescribes an error that might be thrown.@throws {TypeError} If input is invalid.@typeJSSpecifies the type of a variable/property.@type {boolean}@typedefJSDefines a custom type (e.g., object shape).@typedef {{id: number, value: string}} Item@callbackJSDescribes a callback function parameter.@callback MyCallback@enumJSDescribes an enumerated type.@enum {number}{@link}JavaCreates an inline link to other Javadoc.See {@link OtherClass#method}{@code}JavaDisplays text in code font, uninterpreted.Use {@code true} or {@code false}.{@value}JavaDisplays the value of a static final field.Default is {@value DEFAULT_TIMEOUT}.@seeJavaAdds a "See Also" cross-reference.@see OtherClass@sinceJavaIndicates the version feature was added.@since 1.2@authorJavaSpecifies the author of a class/interface.@author Jane DoeThis table provides a quick reference for common tags used across different documentation standards.373.6 Guiding AI Interaction and BehaviorRules can also shape how the developer interacts with the AI.
Rule Examples:

If any of my requests are not clear, ask me to clarify before proceeding. 11
If you have suggestions for a better approach or library, feel free to propose them. 11
For complex features involving multiple file changes, outline the proposed steps and affected files before generating the code.
When asked to debug, explain the steps you are taking and the reasoning behind them. Use console.log / dbg() / System.out.println appropriately to trace execution. 11


3.7 Rules as Proactive Quality GatesWhen .windsurfrules are carefully aligned with the linters, formatters, testing frameworks, and architectural patterns established in a starter repository or project, they elevate the AI's role beyond mere code generation. The AI becomes an active participant in maintaining quality during the development process itself. Starter repositories define the project's quality baseline through their tooling and structure.8 Rules instruct the AI on how to adhere to this baseline.11 By writing rules that explicitly reference these tools and conventions (e.g., "Generate code passing ESLint rules defined in .eslintrc.json," "Write pytest tests using fixtures defined in conftest.py," "Format code using Black according to pyproject.toml"), developers guide the AI, leveraging its contextual understanding 3, to produce code that already meets many of the project's standards. This proactive approach prevents common errors and style inconsistencies before they are committed, contrasting with traditional CI/CD pipelines or manual reviews that detect issues after the code has been written. This effectively "shifts left" the quality enforcement, making the AI a partner in upholding standards from the initial stages of code creation.4. Stack-Specific .windsurfrules for Starter RepositoriesThe following sections provide example .windsurfrules tailored for specific technology stacks, based on the analysis of popular and well-structured starter repositories. These serve as robust starting points, intended for adaptation to individual project needs.4.1 Next.js (TypeScript)Next.js, particularly with the App Router, introduces specific patterns for routing, data fetching, and component types (Server vs. Client). Starter repositories like yaredow/next-starter 8 and AnwarHossainSR/nextjs-15-template 23 establish conventions around these features, along with tooling like TypeScript, Tailwind CSS, ESLint, Prettier, Jest, and potentially Cypress or tRPC.Table: Next.js Starter Repository Feature Comparison
Feature/Toolyaredow/next-starter AnwarHossainSR/nextjs-15-template Key Config FilesRelevant Best Practices SnippetsNext.js VersionImplied >= 13 (App Router likely)15 (App Router)next.config.mjs, package.json8LanguageTypeScriptTypeScripttsconfig.json, package.json8CSSTailwind CSSTailwind CSS v4tailwind.config.js (implied), postcss.config.mjs8UI ComponentsShadcn UICustom components (implied)components.json (Shadcn)8State ManagementNot specified (React Context/Hooks likely)react-query (TanStack Query)package.json23API LayertRPCCustom API Routes/Route Handlers (implied)src/server/api (tRPC implied)8AuthBetter-authNot specified (Prisma likely implies custom or external)package.json8ORMDrizzle ORMPrismadrizzle.config.ts, package.json8LinterESLintESLint (Airbnb config + Next.js + custom).eslintrc.json, .eslintrc.js, package.json8FormatterPrettierPrettier (with Tailwind plugin).prettierrc.json, .prettierrc.js, package.json8Unit TestingJest, React Testing LibraryNot specifiedjest.config.ts, jest.setup.ts, package.json8E2E TestingCypressNot specifiedcypress.config.ts, cypress/, package.json8Git HooksHusky, Lint-StagedHusky, Lint-Staged.husky/, .lintstagedrc.js (implied), package.json8SEOnext-seo, next-sitemapMeta tags, OpenGraph, robots.txt, sitemap supportpackage.json, src/app/layout.tsx (implied)8Other Key LibsReact Email, Resend, Upstash Redis, clsx, tailwind-merge (implied)next-themes, react-query, eslint-plugin-simple-import-sortpackage.json8
Effective .windsurfrules for Next.js must be specific about framework features. Generic instructions like "fetch data" are insufficient given the different data fetching patterns in Server Components versus Client Components, or between the App Router and the older Pages Router.22 The rules need to explicitly guide the AI towards the specific patterns adopted by the starter repository, such as using Route Handlers for APIs, fetching data directly in Server Components using async/await, or marking interactive components with 'use client'. This requires a good understanding of Next.js conventions and the specific choices made in the starter template.Formulated .windsurfrules for Next.js (TypeScript):You are an expert Next.js developer proficient in TypeScript, React, Tailwind CSS, Jest, React Testing Library, ESLint, and Prettier. You build applications using the Next.js App Router.Project Structure & Conventions
Use the Next.js App Router for all routing and layouts. Place pages in src/app/.
Organize reusable components under src/components/.
Place utility functions in src/lib/ or src/utils/.
Place custom hooks in src/hooks/.
Place type definitions in src/types/ or colocated with components/modules.
Use absolute imports starting with @/ mapped to the src/ directory.
Use kebab-case for file names (e.g., user-profile.tsx, api-utils.ts).
Adhere strictly to TypeScript. Avoid any type unless absolutely necessary and provide justification. Prefer type over interface for defining object shapes.
React & Next.js Best Practices
Use functional components and React Hooks.
Default to Server Components. Only use Client Components ('use client') when necessary for interactivity (event handlers, state, lifecycle effects, browser APIs).
Fetch data in Server Components using async/await with fetch or server-side libraries. Avoid useEffect for data fetching in Server Components.
For Client Components, fetch data using Route Handlers or third-party libraries like SWR or React Query (if installed).
Use the Metadata API (export const metadata =...) for SEO in layout.tsx and page.tsx files instead of <Head>. 46
Use next/link for internal navigation.
Use next/image for image optimization.
Implement error handling using error.tsx files and loading states using loading.tsx files within the App Router structure.
Manage environment variables using .env files and access them securely via process.env.
Styling (Tailwind CSS)
Apply styles primarily using Tailwind CSS utility classes directly in JSX.
Follow a mobile-first approach for responsive design using Tailwind's breakpoint modifiers (e.g., md:, lg:).
Use the cn utility function (if available in src/lib/utils.ts) for conditionally merging Tailwind classes.
Define custom colors, fonts, or other theme extensions in tailwind.config.js.
Linting & Formatting (ESLint/Prettier)
Ensure all generated code adheres to the rules defined in .eslintrc.json (or .eslintrc.js). Pay attention to eslint-config-next rules.
Format all generated code according to the rules in .prettierrc.js (or prettier.config.js). Ensure Tailwind classes are sorted if prettier-plugin-tailwindcss is configured.
Follow import sorting rules if configured (e.g., via eslint-plugin-simple-import-sort).
Testing (Jest/React Testing Library)
Generate unit tests for components, hooks, and utility functions using Jest and React Testing Library. Place test files adjacent to the source file (e.g., Button.tsx, Button.test.tsx) or in a __tests__ directory.
Write tests that focus on component behavior from the user's perspective, using RTL queries to find elements.
Mock dependencies (API calls, modules) using Jest's mocking capabilities (jest.fn(), jest.mock()).
Follow the configuration in jest.config.js and jest.setup.ts.
Documentation (JSDoc)
Add JSDoc comments to all exported functions, components, hooks, and types.
Use @param to document function/component props.
Use @returns to document return values for functions/hooks.
Use @typedef for complex object types where appropriate.
API Layer (Example: Route Handlers)
Implement API endpoints using Route Handlers within the src/app/api/ directory structure.
Use standard Request and Response objects.
Ensure proper request validation and error handling.
Maintain type safety between client and server where possible.
General Interaction
If my request is ambiguous, ask for clarification before generating code.
If you propose a solution that involves adding a new dependency, ask for confirmation first.
Feel free to suggest improvements or alternative approaches if you think they align better with best practices.
4.2 Python (Django)Django projects benefit greatly from established structures and conventions. cookiecutter-django 10 is a highly popular and comprehensive template that sets up Django with Docker, environment variable management, custom user models, testing, linting, formatting, and deployment readiness. Other templates might offer lighter starting points.47Table: Django Starter Template Feature Comparison (cookiecutter-django)
Feature/Toolcookiecutter-django Key Config FilesRelevant Best Practices SnippetsDjango VersionUser-selectable (typically latest LTS or stable)requirements/base.txt or pyproject.toml10LanguagePythonpyproject.toml10CSS FrameworkBootstrap (optional, via django-crispy-forms)settings/base.py (INSTALLED_APPS)10 (implied)Frontend JSMinimal/Optional (focus on Django templates)static/10 (implied)WSGI/ASGI ServerGunicorn (production), Django dev server (dev)Procfile (Heroku), Docker setup10 (implied)DatabasePostgreSQL (default), MySQL optionsettings/base.py (DATABASES), .env10Authdjango-allauth (Custom User Model, Social Auth)settings/base.py, users/models.py, users/adapters.py10EmailAnymail (Mailgun, SES, Mailjet, etc. options)settings/base.py, .env10Task QueueCelery (optional)settings/base.py, taskapp/10Cloud ProviderAWS, GCP options (for storage/deployment)settings/production.py (storage backends), Docker/deployment configs10LinterFlake8.flake8, .pre-commit-config.yaml10FormatterBlackpyproject.toml ([tool.black]), .pre-commit-config.yaml10TestingPytest (default) or Unittestpytest.ini (implied), tox.ini, tests/10Git Hookspre-commit.pre-commit-config.yaml10Docker SupportYes (Development and Production)docker-compose.yml, compose/, Dockerfile10Dependency Mgmtpip with requirements/*.txt (default), uv support addedrequirements/, pyproject.toml, uv.lock10DocumentationSphinxdocs/, .readthedocs.yaml10
Django boilerplates often provide extensive pre-built functionality. The role of .windsurfrules here is not just to enforce basic style but to guide the AI in correctly using and extending the boilerplate's established patterns. For instance, rules should direct the AI to use the provided custom User model, place new application code within the designated apps directory, and leverage the configured settings management (like django-environ). Rules should bridge the gap between the generic template and the specific application logic being developed.Formulated .windsurfrules for Django:You are an expert Django developer, proficient in Python 3.11+, Django, Django REST Framework (DRF), pytest, Black, Flake8, Docker, and PostgreSQL. You follow best practices for building scalable and maintainable web applications.Project Structure & Conventions
Place all new Django apps inside the apps/ directory.
Follow the standard Django app structure (models.py, views.py, admin.py, urls.py, forms.py, tests.py or tests/).
Adhere strictly to PEP 8 guidelines.21 Use meaningful variable, function, and class names (snake_case for functions/variables, PascalCase for classes).
Configure settings using environment variables managed by django-environ, accessed via env() in settings/base.py and other environment-specific settings files (development.py, production.py). Do not hardcode secrets or configuration values.
Use relative imports within an app, and absolute imports starting from the project root or apps. for inter-app imports.
Models (Django ORM)
Define models in apps/<app_name>/models.py.
Use appropriate Django field types (e.g., CharField, IntegerField, DateTimeField, ForeignKey, ManyToManyField). Define verbose_name for fields.
Always define a __str__ method for readable object representation.
Add database indexes (db_index=True) to fields frequently used in filtering or ordering where performance benefits are expected.
Use models.Manager for custom queryset methods where appropriate.
Generate migrations using python manage.py makemigration <app_name> and apply them with python manage.py migrate. Keep migrations small and focused.29
Views & Templates
Prefer Class-Based Views (CBVs) for standard CRUD operations and complex logic, but use Function-Based Views (FBVs) for simple cases.
Use Django's generic CBVs (e.g., ListView, DetailView, CreateView, UpdateView, DeleteView) where applicable.
Keep business logic out of views; place it in service layers or model methods.
Organize templates in templates/<app_name>/ directories. Use template inheritance with a base template (templates/base.html).
Use Django template tags and filters; avoid complex logic in templates.21
Ensure all views requiring authentication use appropriate decorators (@login_required) or mixins (LoginRequiredMixin).
Implement CSRF protection for all POST requests.
Django REST Framework (DRF) - If Applicable
Define serializers in serializers.py (usually extending serializers.ModelSerializer).
Use ViewSets (e.g., ModelViewSet) for standard API CRUD operations.
Configure permissions (permissions.py) and authentication classes appropriately in views or globally.
Use DRF's built-in filtering, pagination, and ordering capabilities.
Ensure API endpoints are documented (e.g., using drf-spectacular if configured).
Forms
Use Django Forms (forms.py) for data validation, especially for user input not handled by DRF serializers.
Use ModelForm when the form directly maps to a model.
URLs
Define app-specific URLs in apps/<app_name>/urls.py and include them in the main urls.py using include().
Use named URL patterns (name='...') and reverse URL resolution (reverse() or {% url %}) consistently.
Admin
Register important models in apps/<app_name>/admin.py for access via the Django admin site.
Customize admin views using admin.ModelAdmin subclasses for better usability.
Linting & Formatting (Flake8/Black)
Ensure all generated Python code passes Flake8 checks according to the .flake8 configuration file. Pay attention to complexity limits and potential bugs (e.g., flake8-bugbear checks 20).
Format all generated Python code using Black, adhering to the configuration in pyproject.toml (e.g., line length).
Testing (pytest)
Write tests using pytest. Place tests in apps/<app_name>/tests.py or a tests/ subdirectory within the app.
Use pytest fixtures (defined in conftest.py or locally) for setting up test data and resources.31
Use pytest.mark.parametrize for testing multiple scenarios with the same test function.32
Test models, views, forms, utility functions, and service layers thoroughly.
Use mocking libraries (like unittest.mock accessed via mocker fixture in pytest-mock) to isolate tests from external dependencies (APIs, database calls in unit tests).
Write integration tests that interact with the database (using the test database configured in settings/test.py).
Documentation (Docstrings)
Write docstrings for all modules, classes, functions, and methods using Google or NumPy style.
Docstrings must include a summary line, parameter descriptions (Args:), and return value descriptions (Returns:). Document attributes where relevant.40
Security
Use Django's built-in security features (CSRF, XSS protection).
Keep Django and all third-party dependencies updated.29
Handle SECRET_KEY and other sensitive credentials securely using environment variables (via django-environ).
General Interaction
If my request involves modifying existing boilerplate code (e.g., the User model), confirm understanding of the existing implementation first.
Ask for clarification if requirements are unclear.
Suggest improvements or alternative Django patterns if applicable.
4.3 Java (Spring Boot)Spring Boot applications are often initialized using Spring Initializr, which provides a basic structure. Best practice repositories like arsy786/springboot-best-practices 28 and abhisheksr01/spring-boot-microservice-best-practices 44 demonstrate further conventions around layered architecture, testing strategies (including slices and mocking), code quality tools (Checkstyle, PMD, SonarLint), logging, and dependency management.Table: Spring Boot Best Practices & Tooling Comparison
Feature/Toolarsy786/springboot-best-practices abhisheksr01/spring-boot-microservice-best-practices Key Config FilesRelevant Best Practices SnippetsBuild ToolMavenGradlepom.xml, build.gradle28LanguageJavaJava (>= 21)pom.xml, build.gradle28Core FrameworkSpring BootSpring Bootpom.xml, build.gradle28Web LayerSpring Web MVC (implied)Spring Web MVC (implied)pom.xml, build.gradle53Data AccessSpring Data JPA (implied)Spring Data JPA (implied, Connector pattern mentioned)pom.xml, build.gradle28LoggingSLF4jSLF4j (with Lombok @Slf4j)application.yml, logback-spring.xml (implied)28Testing (Unit/Int)JUnit (implied by starter-test)JUnit 5, Cucumber (E2E), Pitest (Mutation)pom.xml, build.gradle28MockingMockito (implied)Mockito (implied), WireMockpom.xml, build.gradle33Code QualitySonarLintCheckstyle.settings/ (SonarLint), checkstyle.xml28Code CoverageMentionedJacocopom.xml (implied), build.gradle28Security ChecksMentioned (Encrypt sensitive info)OWASP Dependency Check, Trivy (Docker), Snyk (IaC), OWASP ZAP (PenTest)build.gradle (OWASP)28API DocsNot specifiedSpringDoc (OpenAPI 3)build.gradle44Dev AcceleratorsLombokLombok, Mapstructpom.xml, build.gradle28ContainerizationNot specifiedDocker, Hadolint (Dockerfile linter)Dockerfile44CI/CD ExamplesNot specifiedCircleCI, Concourse, Jenkins, Google Cloud Build.circleci/config.yml, pipeline.yml, etc.44
Spring Boot relies heavily on annotations for configuration and component definition. Therefore, .windsurfrules must be precise about annotation usage to ensure the AI generates code that integrates correctly. Rules should specify when to use @Service, @Repository, @Component, differentiate between @Mock and @MockBean based on testing context 33, and guide the use of appropriate test slice annotations like @WebMvcTest or @DataJpaTest.34Formulated .windsurfrules for Java (Spring Boot):You are an expert Java developer specializing in Spring Boot microservices, proficient in Java 17+, Maven or Gradle, Spring Core (DI, IoC), Spring Web (MVC), Spring Data JPA, Spring Security, JUnit 5, Mockito, Checkstyle, Lombok, and Docker.Project Structure & Conventions
Follow standard Maven/Gradle project structure (src/main/java, src/main/resources, src/test/java).
Use reverse domain name convention for package names (e.g., com.example.project).
Place the main application class (annotated with @SpringBootApplication) in a root package above other classes.53
Organize code into layers: controller, service, repository (or dao/connector), dto, model (or entity), exception, config.
Use meaningful and descriptive names for classes (PascalCase), methods (camelCase), and variables (camelCase).27
Spring Core & Configuration
Use constructor injection for dependencies. Annotate constructors with @Autowired.28 Avoid field injection.
Annotate classes with @Service for business logic, @Repository for data access, and @Component for other general components.
Prefer application.yml over application.properties for configuration due to better readability.28
Externalize configuration values; avoid hardcoding. Use @ConfigurationProperties for type-safe configuration binding.
Utilize Spring Profiles (e.g., dev, prod, test) for environment-specific configurations.53
Spring Web (MVC)
Create REST controllers using @RestController.
Use specific mapping annotations (@GetMapping, @PostMapping, @PutMapping, @DeleteMapping, @PatchMapping) with clear path definitions.
Use Data Transfer Objects (DTOs) for request and response payloads to decouple API contracts from internal domain models. Use Lombok (@Data, @Value, @Builder) for DTOs. If Mapstruct is used, define mappers according to its conventions.44
Handle request bodies with @RequestBody and path variables with @PathVariable. Validate request DTOs using Bean Validation (@Valid annotation and constraints like @NotNull, @Size).
Implement centralized exception handling using @ControllerAdvice and @ExceptionHandler.28 Define custom exception classes extending RuntimeException or specific Spring exceptions.
Spring Data JPA
Define JPA entities in the model or entity package using @Entity. Use Lombok (@Data, @NoArgsConstructor, @AllArgsConstructor) for entities, but be cautious with @Data due to potential performance/JPA issues (consider @Getter, @Setter, @ToString, @EqualsAndHashCode separately).
Create repository interfaces in the repository package extending JpaRepository (or other relevant Spring Data repository interfaces).
Use Spring Data query methods or @Query annotation for custom JPQL or native SQL queries.
Manage transactions using the @Transactional annotation, typically at the service layer. Apply it judiciously (read-only for read operations).
Logging
Use SLF4j for logging. Leverage Lombok's @Slf4j annotation for easy logger injection.28
Log meaningful messages at appropriate levels (DEBUG, INFO, WARN, ERROR). Log entry/exit points of key methods at DEBUG level. Log errors with stack traces. Avoid logging sensitive information.
Code Quality (Checkstyle/PMD)
Ensure all generated Java code adheres to the rules defined in checkstyle.xml (or other configured static analysis tool like PMD).25
Pay attention to rules regarding naming conventions, Javadoc, code complexity, potential bugs (e.g., empty catch blocks, unused variables), and formatting.
Testing (JUnit 5 / Mockito)
Write unit tests using JUnit 5 (@Test). Place tests in src/test/java following the same package structure as the source code.
Use Mockito for mocking dependencies in unit tests. Use @Mock for non-Spring dependencies and @InjectMocks to inject them into the class under test. Initialize mocks using @ExtendWith(MockitoExtension.class).33
Write integration tests using @SpringBootTest. Use test slices like @WebMvcTest (for controllers), @DataJpaTest (for repositories), @JsonTest (for JSON serialization) where appropriate to load only necessary parts of the Spring context.34
Use @MockBean to mock Spring-managed dependencies within integration tests (@SpringBootTest or test slices).33
Use assertions from JUnit Jupiter (org.junit.jupiter.api.Assertions) or libraries like AssertJ.
Aim for high test coverage, using tools like Jacoco to measure it.44
Documentation (Javadoc)
Write Javadoc comments for all public classes, interfaces, methods, and constructors.27
Include a summary sentence, @param tags for all parameters, @return tag for non-void methods, and @throws tag for declared exceptions.
Use <code> tags for code elements and follow standard Javadoc formatting conventions (3rd person descriptive).42
Use @since to document when features were added and @author for class/interface authorship.42
Lombok
Utilize Lombok annotations (@Data, @Value, @Getter, @Setter, @ToString, @EqualsAndHashCode, @Builder, @NoArgsConstructor, @AllArgsConstructor, @Slf4j) extensively to reduce boilerplate code.28 Be mindful of the implications of each annotation (e.g., mutability with @Data).
Security
Include spring-boot-starter-security for basic security configuration.
Configure security rules appropriately (e.g., permit/deny access to endpoints).
Handle sensitive configuration (passwords, API keys) securely using environment variables or secrets management tools, not hardcoded in source code or application.yml.28
General Interaction
If a request requires adding a new Spring Boot starter dependency (e.g., spring-boot-starter-cache), confirm before adding it to pom.xml or build.gradle.
Ask for clarification if requirements regarding specific Spring features or configurations are unclear.
Suggest relevant Spring Boot patterns or features if they provide a better solution.
5. Integrating .windsurfrules into Your WorkflowIncorporating .windsurfrules into the development process is straightforward:
Create the File: Add a file named exactly .windsurfrules to the root directory of your project repository.11
Populate with Rules: Add your project-specific rules using the syntax and best practices outlined above. Start with the general best practices and then add or adapt the stack-specific rules relevant to your project or chosen starter template.
Version Control: Commit the .windsurfrules file to your version control system (e.g., Git) so that the entire team benefits from consistent AI guidance. If the file contains sensitive internal conventions, add it to your .gitignore file instead.13
Windsurf automatically detects and utilizes the .windsurfrules file within its corresponding project workspace. The Cascade AI agent will read these rules and factor them into its context when generating code, suggesting changes, or answering questions related to that project.11 The rules act as a persistent layer of guidance, complementing the dynamic context derived from indexed code, open files, and chat interactions.3Treat the .windsurfrules file as living documentation. As project standards evolve, dependencies change, or new patterns emerge, update the rules accordingly. Regularly review and refine the rules collaboratively as a team to ensure they remain clear, effective, and aligned with the project's goals.6. ConclusionThe combination of well-structured starter repositories and carefully crafted .windsurfrules offers a powerful strategy for optimizing AI-assisted development with Windsurf. Starter templates provide a foundation built on best practices, including established project structures, essential tooling (linters, formatters, testers), and common configurations for specific technology stacks.8 The .windsurfrules file allows developers to explicitly communicate these established standards and conventions directly to the Windsurf AI.11By aligning .windsurfrules with the patterns and tools defined in a starter repository, developers can guide Windsurf to generate code that is not only functional but also consistent, maintainable, and compliant with project quality standards from the outset. This synergy transforms the AI from a simple code generator into a proactive quality assurance partner, enforcing coding styles, promoting testing, standardizing documentation, and adhering to architectural patterns during the development process.The stack-specific examples provided for Next.js, Django, and Spring Boot demonstrate how to translate the features of starter templates and general best practices into concrete rules for the AI. Developers are encouraged to use these examples as a starting point, adapting and extending them to match the unique requirements and conventions of their specific projects and teams. As agentic IDEs like Windsurf continue to evolve 2, leveraging mechanisms like .windsurfrules to provide clear, persistent guidance will be increasingly crucial for maximizing productivity and ensuring the quality and consistency of AI-generated code.

A Comprehensive Guide to Configuring Windsurf.ai with windsurfrules1. Introduction to Windsurf.ai and Rule-Based CustomizationThe landscape of software development is continually evolving, with Artificial Intelligence (AI) playing an increasingly significant role in augmenting developer workflows. AI-powered Integrated Development Environments (IDEs) aim to enhance productivity, streamline tasks, and foster a more intuitive coding experience. Among these emerging tools, Windsurf.ai positions itself as a significant advancement, moving beyond simple code completion towards a more collaborative and agentic paradigm. Understanding its core philosophy and customization mechanisms is crucial for leveraging its full potential.1.1 Overview of Windsurf.ai as an Agentic IDEWindsurf.ai is presented as a "next-generation AI IDE" 1 and the "first agentic IDE" 2, designed explicitly to maintain a developer's "flow state".2 Its fundamental approach differs from traditional coding assistants by combining copilot-style collaboration with autonomous agent capabilities.3 This means Windsurf aims not only to suggest code but also to understand context, anticipate needs, and perform complex tasks independently, acting more like an AI partner than a passive tool.Key features underpinning this philosophy include:
Cascade: An agentic chatbot designed for deep collaboration, capable of understanding codebase context, suggesting and running commands, performing multi-file edits, and even picking up work where the developer left off.1 It offers different modes (Write, Chat, Legacy) with varying levels of automation.6
Flows: Described as "Agents + Copilots," this concept represents the synergy between AI collaboration and autonomous task execution, allowing the developer and AI to operate on the same state in real-time.2
Supercomplete: An advanced code completion feature that analyzes context beyond the immediate line to predict the developer's next action.2
Context Awareness: Windsurf emphasizes its deep understanding of the entire codebase, including structure, relationships, and real-time developer actions, facilitated by features like local indexing and embeddings.1
Integrated Tooling: Includes terminal integration (with natural language commands via Cmd/Ctrl + I), inline edits (Cmd/Ctrl + I in editor), image-to-code capabilities, linter integration, and support for Model Context Protocol (MCP) to connect custom tools.1
AI Model Flexibility: Provides access to various large language models (LLMs), including options like Claude 3.5 and Gemini 2.5 Pro.6
This focus on "agentic" capabilities signifies a departure from tools that merely react to immediate typing. Windsurf's AI is designed to perform multi-step, context-aware actions such as creating multiple files, running and debugging scripts, and executing complex refactoring across the codebase.2 Consequently, the mechanisms for guiding this AI must be more sophisticated than simple style configurations. The windsurfrules system serves as this primary directive mechanism, shaping how the AI agent behaves within the development environment. These rules are not just about code aesthetics; they are operational instructions for an AI designed to actively participate in the development process.1.2 The Role and Importance of windsurfrules in Guiding AI Behavior (Cascade)Given Windsurf's agentic nature, directing its behavior effectively is paramount. The windsurfrules system, encompassing both global (global_rules.md) and project-specific (.windsurfrules) files, provides the core mechanism for this customization.1 These files contain custom instructions 13 that guide the AI assistant, particularly the Cascade feature, on how to operate within a specific context.14The primary functions of these rules include:
Providing Context: Rules inform the AI about user preferences, project standards, and specific codebase characteristics that it might not infer automatically.15 This includes preferred coding styles, architectural patterns, technology stacks, and even project-specific terminology or constraints.14
Ensuring Consistency: They act as a "constitutional framework" 14 for the AI, ensuring its outputs and actions remain consistent with project standards over time and across different interactions. This helps prevent "AI drift," where the AI's behavior might diverge from initial expectations due to the probabilistic nature of LLMs or evolving interaction history.14 Without explicit, persistent rules, the AI's suggestions for code structure, naming conventions, or even architectural choices might become inconsistent, undermining maintainability.14 Rules provide a stable reference point, counteracting this potential drift.
Directing Agentic Actions: Beyond static code generation, rules can guide how the AI performs actions like multi-file editing, running commands, or generating tests.2
Enforcing Standards: They help enforce team-wide coding standards, architectural decisions, security practices, and testing protocols, ensuring AI contributions align with established quality bars.14
Neglecting or poorly managing these rules can lead to suboptimal AI performance, inconsistent code generation, deviations from the intended architecture, and ultimately, a decrease in code quality.14 In extreme cases, the loading of malicious rules files could potentially be exploited to introduce vulnerabilities or backdoors into the generated code, although developers remain responsible for reviewing AI suggestions.17 Therefore, establishing a comprehensive and well-maintained set of rules is fundamental to effectively and safely integrating Windsurf.ai into a development workflow.1.3 Understanding Global (global_rules.md) vs. Project-Specific (.windsurfrules) FilesWindsurf provides a two-tiered system for rule definition, allowing for both broad, universal guidelines and tailored, project-specific instructions:

Global Rules (global_rules.md):

Scope: Apply across all projects and workspaces opened within the Windsurf IDE.14
Purpose: Define universal standards, core principles, and default AI behaviors that should be consistent regardless of the specific project context.14 Examples include fundamental coding philosophies (like simplicity, readability), general formatting preferences, or default AI communication styles.14
Location/Access: Managed via Windsurf's settings (e.g., "Manage memories" > "Edit global rules" or File > Preferences > Windsurf Settings > "Global rules").14



Project-Specific Rules (.windsurfrules):

Scope: Apply only to the specific project in which the file resides.13
Purpose: Define parameters, constraints, and guidelines unique to that particular project. This typically includes specifying the project's technology stack, required frameworks, architectural patterns, directory structure, specific naming conventions, or testing protocols relevant only to that project.13
Location/Access: A file named .windsurfrules placed in the root directory of the project.13 Alternatively, content can sometimes be pasted via settings ("Local rules" or "Set Workspace AI Rules").13


Hierarchy and Strategy: Project-specific rules (.windsurfrules) take precedence and can override settings defined in the global global_rules.md file.14 This hierarchical structure necessitates a strategic approach to rule management. Core, universally applicable principles (e.g., "Prioritize readable code," "Avoid unnecessary dependencies") are best placed in global_rules.md to establish a baseline standard and avoid repetition.14 Conversely, details that vary between projects, such as the specific UI framework (React vs. Vue), database choice, required linter configurations, or precise directory layout, should be defined within the respective project's .windsurfrules file.14 This layered approach keeps global rules clean and focused on fundamentals, while ensuring project rules provide the specific context needed for accurate and relevant AI assistance within that project. Placing project-specific details globally would lead to conflicts and irrelevant instructions, while duplicating universal principles in every project file would violate the DRY (Don't Repeat Yourself) principle.2. Crafting Effective Windsurf Rules: Syntax, Structure, and Best PracticesCreating rules that effectively guide Windsurf's AI requires understanding the expected format, structuring principles, and how these rules interact with the AI's broader context awareness. While official documentation on the precise syntax appears limited 1, community examples and developer guidance provide a strong foundation.2.1 File Format and SyntaxWindsurf rules are defined in two key files: global_rules.md for workspace-wide settings and .windsurfrules for project-specific instructions, typically located in the project's root directory.13Regarding the internal format and syntax:
Markdown-like Structure: Numerous examples demonstrate rules organized using Markdown elements like headings (#), bullet points (- or *), and code blocks (```).14 This suggests Markdown is a primary supported format, facilitating readability and structure.
List-Based Rules: Recommendations often suggest using enumerated or bulletized lists for clarity and conciseness.19
XML Tag Grouping (Alternative): A Codeium developer specifically recommended using descriptive <XML> tags (e.g., <coding>, <filesystem>, <communication>) to group related rules.19 While less common in public examples, this approach might enhance organization and potentially aid AI interpretation of distinct rule categories.
Flexibility: The coexistence of Markdown and XML tag examples suggests the system might prioritize the semantic content and structure of the rules over strict adherence to a single syntax variant. The underlying parsing likely focuses on extracting actionable natural language instructions. Therefore, logical grouping and clarity appear more critical than the specific formatting choice (Markdown lists vs. XML tags).
Character Limits: At least for global_rules.md, a character limit exists (one source mentioned 6000 characters 14). This necessitates conciseness and prioritizes impactful rules in the global scope.
Configuration can also sometimes be managed through the IDE settings interface, which may provide an alternative way to edit or paste rule content.132.2 Core Principles for Writing RulesTo maximize the effectiveness of windsurfrules, several core principles should guide their creation:
Specificity: The most valuable rules are highly specific to the user, the project, and its unique context.15 They should communicate constraints, conventions, and preferences that the AI cannot infer from general knowledge or code analysis alone. For instance, specifying the use of a niche internal library or a custom architectural pattern provides more value than stating general language syntax rules.
Clarity and Conciseness: Rules must be unambiguous, short, and to the point.19 Complex or vaguely worded rules can confuse the AI, leading to incorrect or unpredictable behavior. Use clear, direct language.
Contextual Relevance: Focus on providing information the AI lacks.15 This includes project-specific technology choices (frameworks, libraries, versions), architectural decisions, established coding standards (beyond generic ones), required security protocols, or team-specific workflow preferences.14
Logical Grouping: Organize related rules together, either using Markdown headings or potentially XML tags.14 This improves human readability and maintainability, and likely helps the AI process the rules more effectively by understanding the context of each instruction group (e.g., rules for testing vs. rules for styling).
Rule Tagging (Optional but Recommended): Using short, unique tags or abbreviations for key rules or principles (e.g., `` for "Simplicity First") can provide a shorthand reference for the AI when it applies a rule, potentially improving traceability and understanding.14
Balancing Rigor and Flexibility: Rules should provide clear direction but avoid being overly restrictive where adaptability is needed.14 The goal is to guide the AI effectively without hindering its ability to find creative or optimal solutions within the defined constraints.
Comprehensive Coverage: Aim to cover key aspects of the development lifecycle relevant to AI assistance, including code quality, formatting, architecture, testing, security, dependencies, and even AI communication style.14
2.3 Integrating Rules with AI Memories and ContextWindsurf's effectiveness stems from its ability to combine static rules with dynamic context and learned information (Memories). Understanding this interplay is key to writing effective rules:
Static Rules (Long-Term Memory): global_rules.md and .windsurfrules act as the persistent, foundational instruction set for the AI.13 They define the unchanging principles, standards, and constraints for the workspace or project. They serve as the AI's "operating manual" or "long-term memory."
Dynamic Context (Working Memory): Windsurf is designed to be context-aware in real-time.2 It analyzes the current codebase (using local indexing and embeddings 5), tracks developer actions, and can incorporate specific files, documentation URLs, or code snippets provided via @ mentions or uploads.1 This forms the AI's "working memory," constantly updated with the immediate task context.
AI Memories (Learned Context): Windsurf can create "Memories" based on interactions and conversations, allowing it to retain specific learned information or context across sessions.1 This acts like a form of "learned short-term memory," capturing specifics not necessarily encoded in static rules.
Interaction: Rules provide the stable framework within which dynamic context and memories are interpreted and applied.14 For example, a rule might globally define the preferred testing framework (e.g., "Use Pytest for unit tests"). Dynamic context would involve the specific code file being tested. A Memory might store details about a custom Pytest fixture learned during a previous chat session. The AI uses the rule ("Use Pytest") to interpret the dynamic context (the code) and potentially leverage the memory (custom fixture details) to generate an appropriate test.Therefore, rules should focus on establishing the non-negotiable standards and preferences, setting the stage for how the AI should process the dynamic information it gathers from the code, the user, and its own memories.Table 2.1: Windsurf Rule Syntax and Best Practices Summary
AspectRecommendationSupporting InformationRationale/NotesGlobal Rules Fileglobal_rules.mdApplies across all workspaces.14 Accessed via settings.14For universal standards, core principles, default AI behavior.Project Rules File.windsurfrulesLocated in project root.13 Overrides global rules.14For project-specific tech stack, architecture, directory structure, conventions.Syntax OptionsMarkdown (headings, lists, code blocks) or XML-tagged lists.Examples show Markdown.14 Dev recommended XML tags for grouping.19System likely flexible; prioritize clarity and structure over specific syntax.Rule StructureUse enumerated or bulletized lists.19Enhances readability and conciseness.Clear separation of individual instructions.GroupingGroup related rules logically using headings or tags.14Improves organization and AI interpretation.Contextualizes rules (e.g., all testing rules together).Content Principle 1: SpecificityRules should be specific to user/codebase; tell AI what it doesn't know.15Focus on project constraints, non-obvious preferences, internal tools/libs.AI has general knowledge; rules provide specific context it lacks.Content Principle 2: Clarity/ConcisenessKeep rules short, clear, and concise.19Avoid ambiguity; ensure AI understands the instruction.Direct language leads to more predictable AI behavior.Tagging (Optional)Use short tags (e.g., ``) for key rules.14Allows AI to reference specific rules when applying them.Improves traceability and understanding of AI actions.Character Limitglobal_rules.md has a limit (e.g., ~6000 chars).14Necessitates prioritizing high-impact global rules.Keep global rules focused on core, universal principles.Location/ConfigurationPlace .windsurfrules in project root or configure via settings.13Ensures Windsurf finds and applies the rules correctly.Standard location for project configuration.
3. General Instructions and Foundational RulesBefore diving into language-specific or highly technical rules, establishing a foundation of general principles and conventions is essential. These rules often belong in the global_rules.md file as they represent overarching philosophies and baseline expectations for AI behavior across different projects.3.1 Defining Core Principles (e.g., Simplicity, Readability, Maintainability)Instructing the AI on fundamental software development principles helps ensure that generated code prioritizes quality attributes beyond mere functional correctness. While LLMs are trained on vast codebases, they may not inherently optimize for maintainability or simplicity without explicit guidance.Key principles to consider encoding in rules include:
Simplicity (KISS - Keep It Simple, Stupid): Explicitly instruct the AI to prefer simpler solutions over complex ones where functionality is equivalent.21 A rule like - Always choose the simplest practicable solution. Only introduce complex patterns if clearly justified. 14 directs the AI away from unnecessary complexity. This helps counteract the tendency of some models to produce overly elaborate code.
Readability: Emphasize that code must be easily understandable by humans.14 Rules like - Code must be immediately understandable - for humans and machines. 14 set a clear priority. This includes using meaningful names and clear structure.23
Maintainability: Code should be easy to modify and extend.23 This is often a result of simplicity and readability but can be stated as a goal.
DRY (Don't Repeat Yourself): Instruct the AI to avoid duplicating code or logic, promoting reuse through functions, classes, or modules.21 A rule could be - Avoid code duplication. Extract repeated logic into reusable functions or components.
YAGNI (You Aren't Gonna Need It): Guide the AI against implementing features or functionality not explicitly requested or currently required.21 This prevents over-engineering based on anticipated future needs that may never materialize. Rule: - Implement only the requested functionality. Do not add features based on potential future needs.
Explicitly stating these principles acts as a meta-instruction, shaping the AI's generation strategy to align with long-term software quality goals.3.2 Establishing Basic Code Formatting and Style Conventions (Across Languages)Consistent code formatting is fundamental for readability and collaboration.25 While language-specific guides (like PEP 8) provide detailed rules, some basic conventions can be established globally. However, the most effective approach is to align these rules with the project's primary linter and formatter tools.Common formatting aspects to consider for rules:
Indentation: Specify preference (e.g., 4 spaces vs. tabs).29 Rule: - Use 4 spaces for indentation.
Line Length: Define a maximum line length (e.g., 80, 88, 100 characters).29 Rule: - Limit lines of code to a maximum of 88 characters.
Whitespace: Define usage around operators, after commas, inside/outside parentheses/braces.29 Rule: - Surround binary operators (+, -, *, /, =, ==, etc.) with a single space on each side.
Quotes: Specify preference for single (') vs. double (") quotes for strings, ensuring consistency.32 Rule: - Use single quotes (') for string literals unless double quotes avoid escaping.
Semicolons (JavaScript): Define whether semicolons are required or forbidden.32 Rule: - Always terminate statements with semicolons. (or - Never use semicolons at the end of statements.)
Brace Style: Specify preferred brace placement (e.g., K&R style).38 Rule: - Use K&R style for braces (opening brace on the same line).
Alignment with Linters/Formatters: Since Windsurf's Cascade feature can automatically fix linter errors in the code it generates 2, it is highly beneficial to ensure that formatting rules defined in windsurfrules directly match the configuration of the project's established linter (e.g., ESLint, Pylint, Checkstyle) and formatter (e.g., Prettier, Black).25 If rules conflict with the linter, the AI might generate code that is immediately flagged or reformatted, causing confusion or wasted effort. Deriving rules directly from the project's .eslintrc, pyproject.toml, or prettierrc files ensures the AI generates compliant code from the start, creating a seamless workflow where the AI and the automated tooling reinforce the same standards.3.3 Guidelines for AI Communication and Interaction StyleBeyond code generation, rules can shape how the user interacts with the Windsurf AI, making the experience more tailored and productive.
Language and Persona: Specify the desired communication language or even a persona for the AI.15 Rules: - Communicate responses in professional English. or - Act as an expert Python/Django developer when providing explanations.
Tone and Formality: Define the desired tone (e.g., formal, casual, friendly, professional).43 Rule: - Maintain a formal and technical tone in explanations.
Response Length/Verbosity: Control the level of detail in responses (e.g., concise vs. detailed).43 Rule: - Provide concise code examples. Explain logic only when complex or non-obvious.
Proactivity vs. Reactivity: This is particularly important for an agentic tool like Windsurf.2 Define when the AI should take initiative (e.g., suggesting refactoring, automatically fixing bugs) versus when it should wait for explicit instructions. User preferences on this can vary significantly.44 Explicit rules prevent the AI from being perceived as overly intrusive or unhelpfully passive. Examples:

- Never write or modify code files unless explicitly instructed with a command like "Implement", "Refactor", "Fix", or "Update". 19
- Do not start fixing bugs or adding features unless explicitly asked. 19
- When generating code that might have performance implications, proactively mention potential bottlenecks and suggest alternatives. (More proactive style)
- Only provide code suggestions when asked. Focus on answering questions or explaining concepts unless code generation is explicitly requested. (More reactive style)


Setting clear expectations for interaction ensures the AI behaves predictably and aligns with the user's preferred workflow, mitigating potential friction points often encountered with highly autonomous AI agents.4. Structuring Rules for Software Architecture and DesignEffective software development relies on well-defined architecture and consistent design patterns. windsurfrules can play a critical role in guiding Windsurf's AI to generate code that adheres to the project's established architectural and design standards, ensuring consistency and maintainability as the codebase evolves.4.1 Enforcing Project Structure ConventionsMaintaining a consistent and logical project structure is vital for navigation, understanding, and scalability. As AI assistants like Windsurf can create or modify files across the project 2, providing explicit structural rules is essential.Rules should define:
Directory Layout: Specify the standard location for different types of code and artifacts. Examples from rules files include defining paths for core logic (src/core), utilities (src/utils), configuration (src/config), specific feature components (e.g., server/cascade_engine), frontend styles (frontend/styles/), or data storage (server/data/vector_store).14
Directory Naming Conventions: Enforce standards for naming directories (e.g., lowercase-with-dashes for components/auth-wizard).14
File Naming Conventions: Define naming patterns for different file types (e.g., PascalCase for React components like UserCard.tsx, kebab-case for other files).15
Standard Files: While not directly generated by AI typically, mentioning the expected presence and purpose of standard files like README.md, LICENSE, .gitignore can reinforce project structure awareness.48
These structural rules are particularly crucial for Windsurf's multi-file operations, such as those performed by Cascade Write Mode or Flows.2 A clear understanding of the intended layout allows the AI to place newly generated files correctly and make coherent changes across related modules without violating the project's architectural integrity. Without these rules, AI-driven file creation could lead to a disorganized structure or architectural drift.4.2 Guiding AI based on Architectural Patterns (e.g., Layered, MVC, Microservices)Informing the AI about the high-level architectural pattern governing the project helps it generate code that fits naturally within the established design.
Identify the Pattern: State the primary architectural pattern being used (e.g., Layered/N-Tier, Microservices, MVC, Event-Driven, Hexagonal).49 Example rule: - This project follows a Layered Architecture (Presentation, Application/Business Logic, Persistence, Database)..15
Enforce Pattern Constraints: Crucially, rules should also enforce the constraints inherent in the chosen pattern. Simply naming the pattern might not be sufficient. For example, in a Layered Architecture, a key constraint is that layers should generally only interact with adjacent layers.49 A corresponding rule could be: - Code in the Presentation Layer must not directly import modules or call functions from the Persistence or Database Layers. Interactions should go through the Application Layer. This prevents the AI from generating code that violates the pattern's core principles, ensuring structural integrity. Similarly, for Microservices 49, rules might emphasize loose coupling and asynchronous communication where appropriate.
By providing both the pattern name and its key constraints, the rules guide the AI to generate code that is architecturally sound and consistent with the project's design philosophy.4.3 Rules for API Design (e.g., REST, GraphQL best practices)For projects involving API development, rules can ensure that AI-generated endpoints, schemas, and related code adhere to best practices for the chosen API style (e.g., REST or GraphQL).52
Specify API Style: Clearly state whether the project uses REST, GraphQL, or another standard. Rule: - APIs in this project follow REST principles. or - Implement new APIs using GraphQL.
Structure and Naming:

REST: Define conventions for endpoint paths (e.g., resource-based nouns, pluralization), use of HTTP verbs (GET, POST, PUT, DELETE) for CRUD operations.52 Rule: - REST endpoints should use plural nouns for resource collections (e.g., /users, /products). Use standard HTTP methods for actions.
GraphQL: Enforce naming conventions for types (PascalCase) and fields (camelCase).53 Guide schema design regarding queries, mutations, and subscriptions. Rule: - GraphQL schema fields must use camelCase. Types must use PascalCase.


Data Handling: Include rules for request validation (e.g., required fields, data types) and response formatting (e.g., consistent structure for success and error responses). Rule: - All API request payloads must be validated. Return errors using the standard project error format.
Error Handling: Specify how errors should be reported (e.g., standard HTTP status codes for REST, GraphQL error structure 54). Rule: - Use appropriate HTTP status codes for REST API responses (e.g., 400 for validation errors, 404 for not found, 500 for server errors).
Security: Incorporate security best practices relevant to APIs, such as input sanitization to prevent injection attacks, rate limiting, and proper authentication/authorization checks.52 Rule: - Ensure all API endpoints enforce authentication and authorization checks before processing requests.
Comprehensive API rules guide the AI to generate not just the basic structure but also robust, secure, and consistent API implementations.4.4 Incorporating Design Principles (e.g., SOLID)Guiding the AI with fundamental software design principles promotes the creation of modular, flexible, and maintainable code.22 While instructing an AI to simply "follow SOLID" might be too abstract, rules can enforce specific, concrete aspects of these principles.
Single Responsibility Principle (SRP): Encourage classes and functions to have a single, well-defined purpose.22 Anti-patterns like the God Object/God Class violate this.55 Rule: - Classes should have a single responsibility. Avoid classes that manage unrelated concerns (e.g., UI logic, business rules, and data access in one class). Rule: - Functions should perform one task well and ideally be less than 20 lines long..15
Open/Closed Principle (OCP): While harder to enforce directly via simple rules, encourage designs that are open for extension but closed for modification.22 This might translate to rules favoring composition over inheritance or using strategy patterns where applicable.
Liskov Substitution Principle (LSP): Ensure that subclasses can be substituted for their base classes without altering correctness.22 Rules might guide proper use of inheritance and interface contracts.
Interface Segregation Principle (ISP): Promote the use of smaller, client-specific interfaces rather than large, monolithic ones.22 Rule: - Interfaces should be specific to the client's needs. Avoid creating large interfaces with methods unused by implementing classes.
Dependency Inversion Principle (DIP): Encourage depending on abstractions (interfaces) rather than concrete implementations.22 Rules might guide the use of dependency injection patterns or frameworks. Rule: - High-level modules should not depend on low-level modules. Both should depend on abstractions (e.g., interfaces).
By translating abstract principles like SOLID into concrete, actionable rules, developers can effectively guide the AI towards generating code that embodies good design practices, leading to more robust and maintainable systems. Avoiding anti-patterns like God Objects or Spaghetti Code 55 can also be explicitly stated in the rules.5. Implementing Rules for Development Workflow and TestingBeyond code structure and design, windsurfrules can help standardize development workflows, particularly in areas where AI assistance is common, such as testing, dependency management, and version control interactions.5.1 Version Control Guidance (e.g., Commit Messages, Branching Strategy)While Windsurf itself may not directly perform Git commits (though Cascade can run terminal commands 2), it can assist in generating commit messages, suggesting branch names, or providing explanations related to version control workflows. Rules can ensure this assistance aligns with team standards.
Commit Messages: Enforce a standard format, such as Conventional Commits, for clarity and automated changelog generation.48 Rule: - When generating commit messages, follow the Conventional Commits specification (e.g., 'feat: add user login endpoint'). Subject line should be imperative and under 50 characters.
Branching Strategy: If the AI is asked for guidance related to branching (e.g., "What should I name the branch for this feature?"), rules can point towards the team's chosen strategy (Gitflow, GitHub Flow, Trunk-Based).48 Rule: - This project uses the GitHub Flow branching strategy. Feature branches should be short-lived and created from 'main'.
Pull Requests: Guide the generation of PR descriptions or summaries. Rule: - Pull request descriptions should clearly explain the purpose of the change and link to the relevant issue tracker ticket..48
Ensuring AI-generated contributions related to version control adhere to established conventions improves repository history clarity and facilitates smoother collaboration.5.2 Dependency Management RulesManaging external dependencies is critical for functionality, security, and maintainability.58 Rules can guide the AI when it suggests adding or using libraries.
Library Selection: Instruct the AI on criteria for choosing dependencies. Rule: - When suggesting new third-party libraries, prioritize those that are actively maintained, have a compatible license (e.g., MIT, Apache 2.0), and have no known critical security vulnerabilities..14
Version Pinning: Encourage specific versions or compatible ranges, potentially referencing project lockfiles.58 Rule: - When adding dependencies, pin to specific stable versions. Usenpm cior equivalent for installations based on lockfiles.
Security Focus: Emphasize checking for vulnerabilities. Rule: - After suggesting the addition of a new dependency, recommend running a vulnerability scan (e.g.,npm audit,pip-audit)..59
Minimalism: Reinforce the principle of avoiding unnecessary dependencies.14 Rule: - Only add new dependencies when strictly necessary and no existing project dependency provides the required functionality.
Given that vulnerable dependencies are a major security risk 62, incorporating security considerations into dependency-related rules is particularly important for guiding the AI towards safer choices.5.3 Guiding Test Generation (Unit, Integration, E2E; TDD/BDD principles)AI coding assistants are increasingly capable of generating tests 64, making this a prime area for rule-based guidance. Effective rules ensure generated tests are not just present but also well-structured, meaningful, and aligned with the team's testing philosophy.
Specify Framework: Clearly state the testing framework(s) to be used.16 Rule: - Generate unit tests using the Jest framework. or - Use Pytest for unit tests and Playwright for end-to-end tests.
Testing Methodology: Indicate preference for TDD (Test-Driven Development) or BDD (Behavior-Driven Development) principles.68

TDD Rule: - When generating code for a new function, first generate a failing unit test that defines its expected behavior.
BDD Rule: - Write BDD scenarios using the Given-When-Then format. Generate step definitions corresponding to these scenarios.


Test Structure: Enforce patterns like Arrange-Act-Assert (AAA) or Given-When-Then for clarity.16 Rule: - Structure unit tests using the Arrange-Act-Assert pattern.
Test Quality Principles (FIRST): Incorporate guidelines based on FIRST principles (Fast, Independent/Isolated, Repeatable, Self-Validating, Timely).71

Rule (Fast/Isolated): - Unit tests should be fast and isolated. Use mocks or stubs for external dependencies (database, network calls) rather than making real calls..71
Rule (Repeatable): - Tests must produce consistent results regardless of the environment. Avoid dependencies on system time or random factors unless explicitly mocked..72
Rule (Self-Validating): - Tests must include clear assertions to validate expected outcomes. Do not rely on manual inspection of output..71


Mocking/Stubbing: Provide guidance on when and how to use test doubles.73 Rule: - Use Jest's built-in mocking capabilities (jest.mock()) for dependencies.
Combining framework specifics with methodological and structural guidelines ensures the AI generates tests that are not only syntactically correct but also effective, maintainable, and aligned with established testing best practices.5.4 Rules for Code Quality Metrics (e.g., Code Coverage) and Linting (ESLint, Pylint)Linters and static analysis tools are essential for maintaining code quality by enforcing standards and detecting potential issues automatically.25 Code coverage metrics provide insights into testing thoroughness but should be used cautiously.78
Linter Adherence: Since Windsurf can integrate with linters 2, rules should mandate adherence to the project's configured linter ruleset. Rule: - All generated code must adhere to the rules defined in the project's.eslintrc.js configuration file.
Actionable Quality Rules: Instead of setting abstract metric targets like "achieve 85% code coverage," which can lead to low-quality tests 80, focus rules on actions that promote quality. Rule: - When generating new functions or methods, include basic unit tests covering the primary success path and at least one common error scenario. This encourages test creation alongside code generation, naturally improving coverage with meaningful tests.
Complexity Limits: Guide the AI to avoid overly complex code that might be flagged by linters or hinder maintainability. Rule: - Aim for low cyclomatic complexity in functions (e.g., below 10). Refactor complex logic into smaller helper functions..16
By focusing rules on adherence to linters and promoting concrete actions like test generation for new code, the AI is guided towards producing code that meets quality standards in a practical and effective manner.Table 5.1: Mapping Testing Principles to Windsurf Rule Examples
Testing Principle/MethodologyDescriptionExample Windsurf RuleSupporting InformationUnit TestingTesting individual functions/methods/components in isolation.- Generate unit tests using [Framework Name, e.g., Pytest]. Focus on testing a single logical unit per test.64Integration TestingTesting the interaction between different modules or services.- When modifying code involving database interaction, suggest generating integration tests that verify the interaction with a test database.81E2E TestingTesting complete user flows through the application.- For new user-facing features, outline the key E2E test scenarios that should be manually tested or automated using [Framework Name, e.g., Playwright].81TDD (Test-Driven Development)Writing tests before writing the implementation code.- Follow TDD: Before implementing a function, generate its unit test(s) defining expected inputs and outputs.68BDD (Behavior-Driven Development)Defining tests based on user behavior using Given-When-Then format.- Describe application behavior using BDD scenarios (Given-When-Then). Generate corresponding step definitions for [Framework Name, e.g., Cucumber].68FIRST: FastTests should execute quickly.- Unit tests must execute quickly. Avoid real network calls or database access; use mocks/stubs instead.71FIRST: Isolated/IndependentTests should not depend on each other or external state.- Each test must set up its own required state and clean up afterwards. Test execution order should not matter.71FIRST: RepeatableTests should yield consistent results across different environments.- Tests must be repeatable. Avoid dependencies on system time, random numbers, or specific environment configurations unless controlled/mocked.72FIRST: Self-ValidatingTests should automatically determine pass/fail status.- Every test must include explicit assertions (e.g.,assert,expect) to validate the outcome. Do not rely on manual output checking.71FIRST: TimelyTests should be written alongside or soon after the code they test.- Generate unit tests concurrently with the implementation of new functions or methods.71Mocking/StubbingUsing test doubles to isolate the code under test.- Use [Library, e.g., jest.mock(), unittest.mock] to mock external dependencies like API calls or database interactions in unit tests.73Code Coverage FocusMeasuring test thoroughness, but prioritizing quality.- When adding features, ensure core logic and common error paths are covered by unit tests. (Avoid setting specific % targets).78Linter IntegrationAligning generated code with linter rules.- Ensure all generated test code passes the project's checks.2
6. Language and Library-Specific Rule SetsWhile general principles provide a foundation, the most effective AI guidance often comes from rules tailored to the specific programming languages, frameworks, and libraries used in a project. These rules encode idiomatic practices, performance considerations, security nuances, and common pitfalls specific to that technology.6.1 PythonPython's emphasis on readability and its rich ecosystem benefit greatly from specific rules.
Style (PEP 8): Mandate adherence to PEP 8, the official style guide.29

Rule: - All Python code must follow PEP 8 guidelines.
Rule: - Use snake_case for variable and function names. 30
Rule: - Use PascalCase for class names. 83
Rule: - Use 4 spaces for indentation. 29
Rule: - Limit lines to 88 characters. 29 (or another agreed-upon limit)
Rule: - Group imports: standard library, then third-party, then local application imports, separated by blank lines. 29
Rule: - Use docstrings for all public modules, functions, classes, and methods. 15


Idiomatic Python ("Pythonic" Code): Guide the AI towards preferred Python constructs.

Rule: - Use list comprehensions for creating lists based on existing iterables where appropriate, instead of explicit for loops with.append(). 83
Rule: - Use generator expressions(expr for item in iterable)when the full list is not needed immediately, especially for large sequences, to save memory. 84
Rule: - Always use thewithstatement when opening files to ensure they are properly closed. 84
Rule: - Useenumerate()when iterating if both index and value are needed. 85
Rule: - Usedict.get(key, default)orcollections.defaultdictinstead of checkingif key in dictionarybefore access. 84
Rule: - Iterate over dictionary keys and values using.items(). 84
Rule: - Avoid using mutable default arguments (e.g.,def func(a=)) UseNoneas default and initialize inside the function if needed.


Performance: Incorporate common Python performance tips.

Rule: - Use built-in functions and libraries (e.g., map, filter, itertools) where applicable as they are often implemented in C. 87
Rule: - Prefer local variables over global variables within loops or frequently called functions. 83
Rule: - Choose the appropriate data structure (list, tuple, set, dict) based on the use case (e.g., use sets for fast membership testing). 83
Rule: - For numerical operations on large datasets, prefer NumPy arrays and vectorized operations over standard Python lists and loops. 83


Security: Enforce secure coding practices relevant to Python.

Rule: - Never useeval()orexec()on unsanitized user input. 88
Rule: - Sanitize all external input (user input, API responses) before using it in database queries, file paths, or HTML output. 62
Rule: - Use thesecretsmodule for generating cryptographically secure tokens or keys, not therandommodule. 88
Rule: - Use parameterized queries or an ORM (like Django ORM, SQLAlchemy) to prevent SQL injection vulnerabilities. 89
Rule: - Store sensitive configuration like API keys and passwords in environment variables or a secrets management system, not hardcoded in source code. 62


Frameworks (Django/Flask):

Django:

Rule: - Follow Django's design philosophies: loose coupling, less code, DRY. 90
Rule: - Structure projects using reusable Django apps. 91
Rule: - Useselect_relatedfor ForeignKey/OneToOneField lookups andprefetch_relatedfor ManyToManyField/reverse ForeignKey lookups to optimize database queries and avoid N+1 problems. 92
Rule: - Use.only()or.defer()to fetch only necessary model fields for performance-critical queries. 92
Rule: - Use.count()for counting objects instead oflen(queryset). 92
Rule: - Use.exists()to check for object existence instead ofif queryset. 92
Rule: - Adddb_index=Trueto model fields frequently used infilter(),exclude(), ororder_by()clauses. 93
Rule: - Use Django's template system for rendering HTML to leverage built-in XSS protection. 95
Rule: - Always include{% csrf_token %}in POST forms and ensureCsrfViewMiddlewareis enabled. 95


Flask:

Rule: - Structure applications using Blueprints for modularity. 97
Rule: - Use the Application Factory pattern (create_app) for application setup and configuration. 98
Rule: - Access application configuration viacurrent_app.configwithin request or application contexts. 100
Rule: - Load configuration from environment variables or configuration files; avoid hardcoding. 99
Rule: - Use Jinja2 templating with autoescaping enabled (default) to prevent XSS. Avoid the|safefilter on untrusted input. 102
Rule: - Implement CSRF protection using extensions like Flask-WTF or Flask-SeaSurf. 102
Rule: - Utilize caching extensions like Flask-Caching for performance optimization. 104




6.2 JavaScript/TypeScriptGiven the dynamic nature of JavaScript and the added type safety of TypeScript, specific rules are crucial for consistency, performance, and security.
JavaScript Style: Referencing established guides is often effective.

Rule: - Follow the Airbnb JavaScript Style Guide for general coding conventions. 35 (Or Google 38, StandardJS 36, Idiomatic.js 107 depending on team preference).
Rule: - Useconstby default; useletonly for variables that need reassignment. Avoidvar. 35
Rule: - Use single quotes'for strings. 32 (or double quotes, consistently).
Rule: - Always use strict equality (===,!==) instead of abstract equality (==,!=). 37
Rule: - Use modern ES6+ features like arrow functions, destructuring, template literals, and modules where appropriate. 35
Rule: - Avoid common pitfalls: understandthisbinding (or use arrow functions), handle truthy/falsy values explicitly, avoidfor...infor arrays. 108


TypeScript Style and Type Safety: Leverage TypeScript's strengths.

Rule: - Enablestrictmode intsconfig.jsonand adhere to all strict checks (noImplicitAny,strictNullChecks, etc.). 110
Rule: - Avoid using theanytype. Useunknownfor values with uncertain types and perform type checks/guards before use. 110
Rule: - Useinterfacefor defining object shapes and contracts; usetypefor unions, intersections, or aliasing primitives/complex types. 32
Rule: - Use PascalCase for type names, interfaces, enums. Use camelCase for variables, functions, properties. 32
Rule: - Usereadonlymodifiers for properties that should not be reassigned after initialization. 114
Rule: - Annotate array types usingTypesyntax, notArray<Type>. 32
Rule: - Do not use theIprefix for interface names (e.g., useUsernotIUser). 114


Performance (JS/TS): Guide towards V8-friendly patterns and efficient TS usage.

Rule: - Maintain stable object shapes; avoid adding/deleting properties after object creation to aid V8's hidden classes and inline caching. 116
Rule: - Keep functions small and focused to potentially enable V8 inlining. 117
Rule: - Prefer numeric enums or constants over string comparisons in performance-critical code. 118
Rule: - Utilize efficient built-in data structures likeMapandSetover plain objects or arrays for specific use cases (e.g., frequent lookups/additions/deletions). 117
Rule (TS Compilation): - Ensureincremental: trueis set intsconfig.jsonfor faster rebuilds. 115
Rule (TS Compilation): - UseskipLibCheck: trueintsconfig.jsonif not modifying library declaration files. 115
Rule (TS Compilation): - Avoid overly complex or deeply nested generic types that can slow down the compiler. 115


Security (JS/TS): Address common web vulnerabilities.

Rule: - Prevent XSS: Sanitize user input before rendering it into the DOM (use libraries like DOMPurify). Escape output appropriately. Implement a strict Content Security Policy (CSP). 63
Rule: - Prevent CSRF: Use the synchronizer token pattern or double submit cookie pattern (preferably signed/HMAC-based). Utilize theSameSitecookie attribute (LaxorStrict). 102
Rule: - Validate and sanitize all input from external sources (user input, API responses) on the server-side. 63
Rule: - Use secure methods for authentication (e.g., OAuth, JWT with proper handling) and authorization. 63
Rule: - Keep all dependencies (npm packages) updated and scan for vulnerabilities regularly. 61


Frameworks (React/Node.js):

React:

Rule: - Components and Hooks must be pure functions regarding their props and state. 124
Rule: - Call Hooks only at the top level of functional components or other custom Hooks. 124
Rule: - Follow the Airbnb React/JSX Style Guide for component structure, naming, and JSX formatting. 34
Rule: - Avoid prop drilling; use Context API or state management libraries (Redux, Zustand) for global/shared state. 127
Rule: - Use stable identifiers (not array indices) askeyprops for lists. 126
Rule: - Do not modify state directly; always use thesetStatefunction (or the updater function fromuseState). 127
Rule: - UseReact.memo,useMemo, anduseCallbackjudiciously to optimize performance by preventing unnecessary re-renders, but avoid premature optimization. 128
Rule: - Use lazy loading (React.lazyandSuspense) for code splitting and optimizing initial load times. 130
Rule: - AvoiddangerouslySetInnerHTML. If absolutely necessary, ensure the HTML content is rigorously sanitized first (e.g., using DOMPurify). 120
Rule: - Extract reusable stateful logic into custom Hooks (nameduseSomething). 125


Node.js:

Rule: - Embrace asynchronous, non-blocking I/O. Useasync/awaitwith Promises for cleaner async code. 61
Rule: - Avoid blocking the event loop with long-running synchronous code or CPU-intensive tasks. Offload CPU-bound work to Worker Threads. 131
Rule: - Handle errors in asynchronous operations properly usingtry...catchwithasync/awaitor.catch()with Promises. 134
Rule: - Structure applications modularly, potentially using layers (web, logic, data access) or components. 134
Rule: - Separate Expressappdefinition from the HTTPserverstartup logic. 134
Rule: - Use environment variables for configuration, especially secrets. Do not hardcode sensitive data. 63
Rule: - Implement robust input validation for all incoming requests (route parameters, query strings, request bodies). 63
Rule: - Use security middleware (e.g., Helmet.js) to set important security headers. 134
Rule: - Implement rate limiting to prevent DoS and brute-force attacks. 61
Rule: - Use connection pooling for database interactions. 132
Rule: - Implement caching strategies where appropriate. 132
Rule: - Use logging libraries (e.g., Pino, Winston) and configure appropriate log levels for production. 132




Table 6.1: Language/Framework Rule Reference (Selected Examples)
Language/FrameworkCategoryKey Principle/RuleExample Windsurf Rule SnippetSupporting InformationPythonStylePEP 8 Adherence- Follow PEP 8 naming conventions (snake_case for functions/variables, PascalCase for classes).29PythonIdiomsFile Handling- Always use the 'with' statement to open and manage files.84PythonPerformanceData Structures- Use sets for efficient membership testing instead of lists.83PythonSecurityInput Handling- Never use eval() on untrusted input. Sanitize all external data.88DjangoPerformanceORM Optimization- Use select_related and prefetch_related to optimize queries involving related objects and prevent N+1 problems.92DjangoSecurityCSRF Protection- Ensure all POST forms include the {% csrf_token %} tag.95FlaskStructureModularity- Organize application logic using Blueprints.97FlaskSecurityXSS Prevention`- Use Jinja2 autoescaping. Avoid the 'safe' filter on user-controlled input.`JavaScriptStyleEquality- Always use strict equality operators (=== and!==).37JavaScriptIdiomsModern Features- Prefer const/let over var. Utilize ES6+ features like arrow functions and destructuring.35TypeScriptType SafetyStrictness- Enable 'strict': true in tsconfig.json. Avoid using the 'any' type; prefer 'unknown' with type guards.110TypeScriptStyleNaming- Use PascalCase for types/interfaces/enums and camelCase for variables/functions.32ReactCore RulesHooks- Only call Hooks at the top level of React functional components or custom Hooks.124ReactPerformanceRendering- Use React.memo, useMemo, and useCallback to prevent unnecessary re-renders for expensive components or calculations.128ReactSecurityXSS Prevention- Avoid using 'dangerouslySetInnerHTML'. Sanitize any HTML content before rendering.120Node.jsPerformanceEvent Loop- Write non-blocking, asynchronous code using async/await. Offload CPU-intensive tasks to Worker Threads.131Node.jsSecurityInput Validation- Validate and sanitize all incoming request data (params, query, body) on the server-side.63
(Note: This table provides illustrative examples. A comprehensive rule set would contain many more specific rules for each category.)7. Advanced Rule Considerations and MaintenanceBeyond language-specifics and foundational principles, crafting a truly comprehensive rule set involves addressing advanced topics like security and performance in detail, and establishing processes for maintaining and evaluating the rules themselves.7.1 Handling Security Rules (OWASP Top 10, Secure Coding Practices)Security cannot be an afterthought, and windsurfrules provide an opportunity to embed secure coding practices directly into the AI's guidance. Given that AI-generated code can inherit vulnerabilities from training data or simply fail to consider security implications 65, explicit security rules are vital.
Specificity is Key: Vague rules like "Write secure code" are ineffective. Rules should target specific vulnerability classes, ideally referencing established standards like the OWASP Top 10 95 or Secure Coding Practices.88
Input Validation and Output Encoding: These are fundamental for preventing injection attacks (SQLi, Command Injection) and Cross-Site Scripting (XSS).

Rule (SQLi): - Always use parameterized queries or well-vetted ORM methods for database interactions. Never construct SQL queries directly using unsanitized user input (OWASP A03:2021). 89
Rule (XSS): - Sanitize all data originating from untrusted sources before rendering it in HTML context. Use context-aware output encoding (e.g., Django/Jinja2 autoescaping, DOMPurify for JS). (OWASP A03:2021) 63


Authentication and Authorization: Guide the AI on implementing secure auth mechanisms.

Rule: - Implement robust authentication checks on all protected endpoints. Use standard, secure methods like OAuth 2.0 or JWT with appropriate security measures (e.g., short expiry, HTTPS-only cookies). 63
Rule: - Enforce authorization (access control) checks on every request for protected resources, ensuring users only access data they are permitted to see (Principle of Least Privilege). 63


Dependency Security: Address risks from third-party libraries.

Rule: - When adding dependencies, check for known vulnerabilities using tools likenpm auditorpip-audit. Prefer libraries with active maintenance. 59


Secure Configuration: Prevent exposure of sensitive information.

Rule: - Store secrets (API keys, passwords, tokens) securely using environment variables or a dedicated secrets management service. Never hardcode secrets in source code. 62


Cryptography: Ensure proper use of cryptographic functions.

Rule: - Use strong, standard algorithms for hashing passwords (e.g., bcrypt, scrypt) with unique salts per user. 88
Rule: - Use strong, modern algorithms for encryption (e.g., AES-256-GCM) with proper key management practices. 62


Linking rules to specific OWASP categories or secure coding principles provides clear, verifiable instructions and helps ensure the AI assistant contributes positively to the application's security posture. However, developers must remain vigilant and always review AI-generated code for security implications, as rules alone cannot guarantee security.177.2 Performance Optimization RulesWhile premature optimization should be avoided 21, rules can guide the AI towards established performance patterns and away from known bottlenecks, particularly those relevant to the specific language or framework.
Focus on Patterns, Not Micro-optimizations: Rules should promote efficient architectural choices and coding patterns rather than low-level tweaks that might offer negligible gains or increase complexity.
Asynchronous Operations: Especially relevant for I/O-bound applications (e.g., Node.js).

Rule: - In Node.js, always use asynchronous APIs for I/O operations (file system, network). Avoid synchronous counterparts that block the event loop. 131


Database Query Optimization: Crucial for data-driven applications (e.g., Django, Flask with ORMs).

Rule: - In Django ORM, useselect_relatedandprefetch_relatedto efficiently fetch related objects and avoid N+1 query problems. 92
Rule: - Utilize database indexing (db_index=Truein Django models) for fields frequently used in query filters or ordering. 93


Caching: Recommend caching strategies where appropriate.

Rule: - Consider caching frequently accessed data that changes infrequently. Use appropriate cache invalidation strategies. 93


Efficient Data Structures/Algorithms: Guide towards efficient built-ins or standard library functions.

Rule: - Use Python's built-in functions and data structures (e.g., sets for membership tests, dicts for lookups) where appropriate for better performance. 83
Rule: - Avoid unnecessary string comparisons in performance-sensitive loops; use integers or enums if possible. 118


Frontend Rendering (React):

Rule: - Apply memoization (React.memo,useMemo,useCallback) to React components only when profiling indicates a significant performance benefit from preventing re-renders. 128
Rule: - Use list virtualization techniques (e.g., react-window, react-virtualized) for rendering very large lists. 128


These rules guide the AI towards writing code that is performant by default, leveraging known best practices for the relevant technology stack, without falling into the trap of premature micro-optimization.7.3 Strategies for Maintaining and Evolving Rule SetsRule sets are living documents that require ongoing maintenance to remain effective as projects evolve, technologies update, and team standards change.13 Treating rule files (global_rules.md and .windsurfrules) as integral parts of the codebase is the most effective maintenance strategy.
Version Control: Store rule files in the project's version control system (e.g., Git).48 This allows tracking changes, reverting to previous versions, and managing different rule sets across branches if necessary.
Code Review for Rules: Changes to rule files should undergo the same review process as production code changes.25 This ensures that new rules are clear, correct, non-conflicting, and aligned with team consensus.
Documentation: Document the purpose and rationale behind complex or non-obvious rules, either within the rule file itself (using comments) or in separate project documentation.140 This helps future maintainers understand why a rule exists.
Ownership and Process: Define clear ownership for maintaining the global and project-specific rule sets. Establish a process for proposing, reviewing, and implementing rule changes.
Regular Updates: Periodically review and update rule sets to reflect changes in project requirements, adopted technologies, updated best practices, or lessons learned from development experience.140 Align rules with updates to linters or formatters.
By applying standard software development practices to the management of rule files, teams can ensure their AI guidance remains accurate, relevant, and maintainable throughout the project lifecycle.7.4 Evaluating Rule Effectiveness and IteratingCreating rules is only the first step; verifying that they positively impact AI behavior and developer productivity is crucial.137 Evaluating rule effectiveness is an iterative process, much like prompt engineering or software development itself.143Methods for evaluation include:
Qualitative Feedback: Regularly solicit feedback from developers using Windsurf with the defined rules.16 Are the AI's suggestions more helpful? Is the generated code more consistent with standards? Does the AI interaction feel more productive? Are there rules that seem ineffective or counterproductive?
Code Review Analysis: Observe patterns in code reviews. Are reviewers spending less time commenting on style or patterns covered by the rules? Are AI-generated code contributions requiring fewer corrections related to rule-covered topics? 148
Linter/Static Analysis Reports: Monitor reports from linters and static analysis tools. Is there a reduction in violations related to rules enforced via windsurfrules? 27
Acceptance Rate of Suggestions: While potentially harder to track formally, observe how often developers accept AI suggestions generated under the influence of the rules versus rejecting or heavily modifying them.137
Task Completion Time (Targeted): For specific, repeatable tasks where AI assistance is often used (e.g., generating unit tests, refactoring specific patterns), measure completion time before and after implementing relevant rules, although this can be difficult to isolate.16
Error Rate Analysis (Targeted): Track the frequency of specific types of bugs or inconsistencies that the rules are designed to prevent.16
Based on this evaluation, rules should be refined, added, or removed iteratively. If a rule isn't producing the desired effect or is causing unintended negative consequences (e.g., making the AI too rigid), it should be adjusted or removed. This continuous feedback loop ensures the rule set evolves to provide maximum benefit.8. Conclusion and RecommendationsWindsurf.ai, as an agentic IDE, offers powerful capabilities for accelerating software development by combining collaborative assistance with autonomous task execution. However, harnessing this power effectively requires careful guidance. The windsurfrules system, encompassing both global (global_rules.md) and project-specific (.windsurfrules) files, serves as the primary mechanism for developers to customize and direct the AI's behavior, ensuring its contributions align with project standards, architectural decisions, and quality expectations.8.1 Summary of the Plan for Comprehensive Rule SetupCreating a comprehensive set of rules involves a structured, layered approach:
Foundation: Start with global_rules.md to define universal core principles (simplicity, readability, DRY), basic cross-language formatting conventions (aligned with linters/formatters), and preferred AI interaction styles (language, tone, proactivity level).
Architecture & Design: Within project-specific .windsurfrules, define the project's structure (directory layout, naming conventions), the primary architectural pattern and its constraints (e.g., Layered, MVC), API design standards (REST/GraphQL), and concrete rules reflecting key design principles (e.g., aspects of SOLID).
Workflow & Testing: Add rules governing interactions with version control (commit messages), dependency management (selection criteria, security checks), and crucially, test generation (frameworks, methodologies like TDD/BDD, quality principles like FIRST).
Language & Framework Specifics: Layer in detailed rules tailored to the specific languages (Python, JS/TS) and frameworks (Django, Flask, React, Node.js) used in the project, covering idiomatic practices, performance patterns, and security considerations unique to those technologies.
Advanced Concerns & Maintenance: Incorporate specific security rules (referencing OWASP), performance pattern guidance, and establish processes for maintaining, versioning, reviewing, and evaluating the rule sets themselves as if they were code.
8.2 Final Recommendations for Effective Windsurf.ai CustomizationTo maximize the benefits of windsurfrules and effectively customize Windsurf.ai:
Start Small and Iterate: Don't attempt to create a perfect, exhaustive rule set from day one. Begin with high-impact global rules and foundational project rules. Gradually expand and refine the rules based on experience and evaluation.
Collaborate with Your Team: Rule definition, especially for project standards, should be a team effort. Involve developers in defining, reviewing, and refining rules to ensure buy-in and shared understanding.25
Treat Rules as Code: Apply software development best practices to your rule files. Use version control, conduct reviews for changes, and document complex rules.48 This ensures maintainability and reliability.
Prioritize Specificity and Context: Focus rules on providing information the AI lacks – project-specific constraints, non-obvious conventions, internal tooling, architectural decisions.15 Avoid generic rules the AI likely already knows.
Align with Existing Tooling: Ensure rules complement and align with configurations for linters, formatters, and testing frameworks used in the project to create a consistent and reinforcing environment.2
Evaluate and Refine Continuously: Regularly assess the impact of the rules through developer feedback and objective measures where possible. Be prepared to modify, add, or remove rules based on their effectiveness.16
Stay Informed: The landscape of AI coding assistants and best practices is evolving rapidly. Monitor Windsurf updates, community discussions, and shared rule repositories for new ideas and improvements.12
By implementing a thoughtful, structured, and iterative approach to creating and maintaining windsurfrules, development teams can effectively guide Windsurf.ai's powerful agentic capabilities, leading to more consistent, maintainable, secure, and high-quality code, ultimately enhancing developer productivity and satisfaction.


Modular Rule Sets for AI Coding Assistant GuidanceIntroductionAI coding assistants, such as Windsurf's Cascade, Cursor, and others, offer significant potential to accelerate software development.1 However, their effectiveness is heavily dependent on the guidance provided.3 Unguided AI can lead to inconsistent code, architectural drift, security vulnerabilities, and deviations from established best practices.3 To harness the power of these tools effectively, clear, consistent, and context-aware instructions are necessary.These instructions are often provided through configuration files, commonly referred to as rules files (e.g., .windsurfrules, global_rules.md, .cursorrules).3 These files act as a "constitutional framework" for the AI, defining coding philosophies, project-specific parameters, and workflow standards.3This document outlines a structured approach for creating a comprehensive set of modular rule files. By separating rules based on specific languages, architectural patterns, testing strategies, API styles, frameworks, or other distinct topics, development teams can create a flexible and maintainable system for guiding AI assistants. This modularity allows teams to apply relevant rulesets to different projects or parts of a project, ensuring the AI's output aligns with specific technical contexts and established best practices. The goal is to enhance AI consistency, improve code quality, maintainability, and security across diverse development scenarios.41. Rule File Fundamentals (windsurf_rules_basics.md)This foundational module should define the basic mechanics and purpose of AI rule files, applicable to systems like Windsurf or Cursor.
Purpose: Explain that rule files provide explicit instructions and context to the AI assistant (like Windsurf's Cascade) to guide its behavior during code generation, refactoring, and analysis.4 They help prevent "AI drift" and ensure consistency.3
File Types and Scope:

Project-Specific Rules: Typically defined in a file like .windsurfrules (or .cursorrules, .aiderrules) placed in the project's root directory.5 These rules provide context specific to the current project, such as technology stack, directory structure, and project-specific conventions.3 They can override global settings for granular control.3
Global Rules: Apply across all projects for a user. Often stored in a file like global_rules.md.3 These define universal guidelines, core coding philosophies, and workflow standards.3 Windsurf allows editing global rules via settings or directly.3


Syntax and Format:

Rule files generally use a Markdown-like syntax, supporting headings, lists (bulleted or enumerated), and potentially code blocks.9
Rules should be short, clear, and concise.9
Grouping related rules is recommended, potentially using structures like XML tags (<communication>, <coding>) for better organization, as suggested by a Codeium developer for Windsurf rules.9


Capabilities (Inferred from Examples): Rules can guide the AI on code style, naming conventions, technology stack choices (including explicitly avoiding certain technologies), architectural patterns, project structure, security considerations, testing strategies, documentation standards, and even define the AI's persona or communication style.3
Activation and Usage: Rules are typically activated by placing the file in the project root (.windsurfrules) or configuring global rules through IDE settings.5 The AI processes these rules as context during generation.4 Referring to a rule file once might be sufficient for the AI to remember its contents for subsequent interactions within a session or project.5 Windsurf's Cascade feature is designed to be aware of real-time actions and context, potentially reducing the need for repeated instructions.12
Limitations and Considerations:

global_rules.md in Windsurf has a character limit (e.g., 6,000 characters); content exceeding this limit may be ignored.3
Rule effectiveness depends on the AI model's ability to interpret and follow instructions. Complex or ambiguous rules may be ignored or misinterpreted.4
Excessive rules might increase processing overhead or latency.4
Security implications exist: Malicious rule files could potentially manipulate AI behavior to introduce vulnerabilities or leak data, although platforms may place responsibility on the user for managing this risk.13


Community and Evolution: The practice of using rule files is adopted by multiple AI coding tools.5 There are community efforts to share and curate effective rule sets (e.g., awesome-windsurfrules repositories).8 This collaborative aspect suggests that best practices for writing rules are evolving, and referencing community examples can be beneficial.3
2. General Development Principles (principles_general.md)This module establishes high-level software design principles that should underpin all coding activities, providing a philosophical foundation for more specific rules.
DRY (Don't Repeat Yourself):

Principle: Every piece of knowledge or logic must have a single, unambiguous, authoritative representation within a system.15 Avoid duplicating code, data, or logic.15
Rationale: Duplication makes code harder to maintain (changes need to be made in multiple places), increases the risk of bugs (inconsistencies), and leads to bloat.15
Application: Use functions, classes, modules, or other abstractions to reuse code.15 Refactor to eliminate redundancy.16 Applies to data (e.g., configuration) and algorithms.16 The opposite is WET (Write Everything Twice / Waste Everyone's Time).16 Duplication Is Evil (DIE) is a related concept.16
AI Rule Example: "Identify repeated blocks of code and refactor them into reusable functions or components."


KISS (Keep It Simple, Stupid):

Principle: Most systems work best if kept simple rather than made complex; simplicity should be a key goal, and unnecessary complexity should be avoided.15 "Do the simplest thing that could possibly work".15 Perfection is achieved when there is nothing left to take away.16
Rationale: Simple code is easier to write, understand, read, debug, and modify.15 It leads to fewer bugs and often better performance.16
Application: Use clear and purposeful names.16 Keep functions/classes focused (Single Responsibility Principle is related).16 Avoid overly clever or obscure logic.19 Delete redundant code/processes.16 Prefer simple solutions unless complexity is clearly justified.3
AI Rule Example: "Prioritize the simplest practicable solution. Only introduce complex patterns or dependencies if clearly justified and explicitly approved." 3


YAGNI (You Aren't Gonna Need It):

Principle: Always implement features only when you actually need them, never when you just foresee that you might need them in the future.15 Remove unnecessary functionality or logic.16
Rationale: Avoids wasting time writing code that isn't needed or turns out differently than anticipated.15 Keeps the codebase cleaner and less polluted with speculative features.15 Avoids premature optimization.15
Application: Focus on current requirements. Resist adding features "just in case". This doesn't preclude designing for flexibility, but avoids over-engineering based on future guesses.15 Experience helps in identifying truly unnecessary code.16
AI Rule Example: "Implement only the functionality explicitly requested. Do not add features or options based on potential future needs unless specified."


SOLID Principles: (Briefly mention as foundational for OO design, details might be language-specific)

Concept: An acronym representing five principles of object-oriented design aimed at creating more understandable, flexible, and maintainable systems.15 Promotes loose coupling and high cohesion.
Principles:

Single Responsibility Principle (SRP): A class/module should have only one reason to change (do one thing).15
Open/Closed Principle (OCP): Software entities should be open for extension but closed for modification.15
Liskov Substitution Principle (LSP): Subtypes must be substitutable for their base types without altering correctness.15
Interface Segregation Principle (ISP): Clients should not be forced to depend on interfaces they do not use.15
Dependency Inversion Principle (DIP): Depend upon abstractions, not concretions.15


Rationale: Leads to systems that are easier to understand, maintain, test, and reuse.16
AI Rule Example: "When designing classes, ensure each class adheres to the Single Responsibility Principle."


Code for the Maintainer / Readability:

Principle: Write code as if the person maintaining it is a "violent psychopath who knows where you live".15 Code is read more often than written.21 Prioritize readability and clarity.3
Rationale: Improves maintainability, reduces debugging time, facilitates collaboration, and makes onboarding easier.6
Application: Use clear names, consistent formatting, appropriate comments, simple logic (related to KISS). Follow the Boy-Scout Rule: leave the code cleaner than you found it.15
AI Rule Example: "Prioritize code readability above all else. Ensure code is immediately understandable to human developers." 3


These overarching principles provide a crucial context for the AI. Guiding the AI with these philosophies helps ensure that generated or modified code is not just functional but also well-designed, maintainable, and less prone to future issues. They form the basis upon which more specific language, framework, or pattern rules are built.153. Code Style & Formatting (code_style_general.md)This module focuses on the consistent visual presentation and syntactic structure of code, which significantly impacts readability and maintainability.
Consistency: The single most important rule is consistency.23 Whatever style is chosen for a project should be applied uniformly throughout the codebase.23

Rationale: Consistency reduces cognitive load, makes code predictable and easier to navigate, improves collaboration, and prevents style debates.6
AI Rule Example: "Adhere strictly to the established coding style guide for this project/language. Maintain consistency in formatting, naming, and structure."


Style Guides: Adopt a standard style guide for the language/project (e.g., PEP 8 for Python 29, Airbnb/Standard/Google for JavaScript 22, Google/Airbnb for TypeScript 33). Document the chosen guide.6

Rationale: Provides a clear, agreed-upon set of rules, leveraging community consensus and experience.22
AI Rule Example: "Follow the conventions outlined in the." 10


Naming Conventions: Use meaningful, descriptive, and intention-revealing names for variables, functions, classes, etc..6

Follow language-specific conventions (e.g., snake_case for Python variables/functions 29, camelCase for JavaScript/TypeScript variables/functions 10, PascalCase for classes 10).
Avoid single-letter names (except simple loops/exceptions).20 Use pronounceable names.20 Avoid ambiguous abbreviations.20 Use consistent vocabulary (no synonyms for the same concept).20
Constants typically use UPPERCASE_WITH_UNDERSCORES.10
Boolean variables often use prefixes like is or has.29
Function names should typically be verbs describing the action.29
Avoid embedding type information in names if the type system makes it clear.37
AI Rule Example: "Use descriptive camelCase names for variables and functions. Use PascalCase for classes." 10


Whitespace: Use whitespace consistently to improve readability.20

Indentation: Use a consistent style (e.g., 4 spaces for Python 20, 2 spaces for JavaScript/TypeScript often 22). Avoid mixing tabs and spaces.23 Use EditorConfig to help manage this.23
Around Operators: Use single spaces around binary operators (=, +, *, ==, etc.).18
Inside Brackets/Parentheses: Generally, avoid extra spaces immediately inside parentheses, brackets, or braces.20
After Commas/Colons: Use a single space after commas and colons, not before.38
Blank Lines: Use blank lines purposefully to separate logical sections of code (e.g., between functions/methods, logical blocks within functions).20 Avoid excessive blank lines.10
Trailing Whitespace: Avoid trailing whitespace at the end of lines or on blank lines.20 Consider pre-commit hooks to remove it.23
AI Rule Example: "Use 2 spaces for indentation. Place single spaces around binary operators. Avoid trailing whitespace."


Line Length: Limit line length (e.g., 79/88 characters for Python 20, often 80 or 100 for JavaScript/TypeScript) to improve readability, especially in side-by-side diffs.20 Use appropriate line-breaking techniques (e.g., wrapping inside parentheses, hanging indents).29

AI Rule Example: "Limit lines to a maximum of 80 characters. Break longer lines logically, preferably using parentheses for grouping."


Quotes: Use single (') or double (") quotes consistently for strings.23 Choose one style and stick to it.23 Many modern JS/TS guides prefer single quotes.22 Use template literals (`) for interpolation or multi-line strings.32

AI Rule Example: "Use single quotes (') for all strings unless double quotes are required for escaping or JSON compatibility."


Semicolons (JavaScript/TypeScript): Choose a style (always use or never use) and apply it consistently.22 Airbnb/Google require them 40; StandardJS forbids them.22 Linters/formatters are essential for enforcement.

AI Rule Example (StandardJS style): "Do not use semicolons at the end of statements."
AI Rule Example (Airbnb style): "Always use semicolons at the end of statements."


Tooling (Linters and Formatters): Use tools like ESLint, Pylint, Flake8, Ruff for linting (checking style and potential errors) and Prettier, Black, YAPF for automatic formatting.6

Rationale: Automates enforcement, ensures consistency without manual effort, catches errors early, allows teams to focus on logic over style debates.6 Integrate into IDEs, pre-commit hooks, and CI/CD pipelines.41
AI Rule Example: "Ensure generated code adheres to the project's ESLint and Prettier configurations. Automatically fix any linting or formatting errors introduced." 48


Establishing and enforcing a consistent code style is foundational for collaborative software development. While specific rules may vary between guides, the core principles of consistency and readability remain constant. Automated tooling is indispensable for maintaining these standards effectively, freeing developers (and AI assistants) to focus on functional requirements.6 AI assistants should be explicitly instructed to adhere to the project's chosen style guide and linter/formatter configurations.484. Documentation Standards (documentation_standards.md)This module provides guidelines for documenting code effectively, ensuring clarity for both human developers and potentially the AI itself.
Importance: Good documentation facilitates onboarding, improves team coordination and collaboration, aids quality assurance, testing, and debugging, and makes code more maintainable.50
Types of Documentation:

Inline Comments (// or #): Use for explaining specific, non-obvious implementation details, complex logic sections, or the "why" behind a piece of code.21 Use sparingly; avoid commenting on obvious code.18 Keep them close to the code they describe.50 Start with the comment marker followed by a space.30 These are primarily for developers maintaining the code.37
Block Comments (Python): Use for longer explanations within code. Indent to the same level as the code, start each line with # and a space, separate paragraphs with a line containing a single #.30
Docstrings (Python) / JSDoc (JavaScript/TypeScript): Use for documenting modules, classes, functions, and methods, especially public APIs.10 These are often used by documentation generation tools and IDEs.37

Syntax: Python docstrings use triple quotes ("""Docstring goes here."""). JSDoc uses /**... */.37
Content: Explain the purpose of the element, describe parameters (@param {type} name - description in JSDoc 51), return values (@return {type} description in JSDoc 51), any exceptions raised, and side effects.51 Avoid merely restating the name or type unless adding clarification.37


README Files: Essential for every project.50 Should provide a project overview, purpose, setup/installation instructions, usage examples, and contribution guidelines.50 Often the first point of entry for new developers or users.
External Guides/Wikis: For architectural overviews, tutorials, in-depth explanations of complex features, or design decisions.51 Often reside in a /docs folder or a wiki.50


Content Best Practices:

Clarity and Conciseness: Use clear, plain language.50 Be concise but explain necessary complexity.50 Use active voice.50
Examples: Provide practical code examples to illustrate usage.50 Ensure examples are correct and runnable.50
Audience: Tailor documentation to the intended audience (e.g., end-users vs. contributing developers).37
Structure: Organize documentation logically with clear headings, lists, and potentially diagrams.50 Use Markdown effectively where appropriate (READMEs, external docs).51
Completeness: Document module dependencies 51, error scenarios 50, configuration options 50, limitations 50, and security considerations.50


Maintenance ("Docs-as-Code"):

Keep Documentation Updated: Documentation must evolve with the code.50 Outdated documentation is misleading and harmful. Tie documentation updates to code changes (e.g., in pull requests).50
Location: Keep documentation close to the code it describes (e.g., docstrings within code, README in root, module docs in module folders).50
Versioning: Use version control for documentation alongside code.50 Maintain changelogs.50 Archive old versions.50
Review: Review documentation as part of the code review process.50 Check for accuracy, clarity, and completeness.
Timestamps/Expiration: Consider adding "Last Updated" timestamps or even expiration dates to encourage reviews.50


Tooling: Leverage documentation generation tools (e.g., Sphinx for Python, TypeDoc for TypeScript) that parse docstrings/JSDoc.51 Utilize IDE features for viewing and generating documentation skeletons.50 Consider automated checks for documentation coverage or broken links.50
A critical aspect emerging from these practices is the distinction between different types of documentation serving different audiences. Inline comments clarify implementation details for maintainers, while formal documentation like JSDoc, docstrings, and READMEs serve consumers or users of the code.37 AI assistants should be guided to generate the appropriate type and level of detail based on this context. Furthermore, treating documentation as an integral part of the development lifecycle—kept in version control, updated with code changes, and subject to review—is essential for maintaining its value.50 Rules should encourage this "docs-as-code" approach.5. Foundational Security Principles (security_general.md)This module outlines fundamental security principles that should guide all software development, forming the basis for language- and framework-specific security rules. The overarching goal is a "secure by design" approach.53
Secure by Design Mindset: Security must be integrated from the beginning of the development lifecycle, not treated as an afterthought.53 This involves proactive measures and continuous security practices.53
OWASP Top 10 Awareness: Use the OWASP Top 10 list as a reference for common web application vulnerabilities and ensure practices address these risks.54
Core Security Practices (Based on OWASP & General Principles):

Input Validation: Rigorously validate, sanitize, and potentially encode all input from untrusted sources (users, external APIs, files) before processing or storing.54 This is the primary defense against injection attacks (SQLi, Command Injection, XSS).54 Address metacharacters carefully.56
Output Encoding: Encode data appropriately for the context in which it will be rendered (HTML, JavaScript, CSS, URL) before sending it to the client.56 This is the primary defense against Cross-Site Scripting (XSS).60 Use context-aware encoding libraries/framework features.60
Authentication: Implement robust authentication mechanisms.58 Use multi-factor authentication (MFA) where appropriate.58 Protect against brute-force attacks (e.g., rate limiting, account lockout).63 Securely handle password resets.
Session Management: Use secure session management techniques.58 Generate strong, unpredictable session IDs.64 Rotate session IDs regularly or upon privilege changes.64 Securely invalidate sessions on logout/timeout.64 Use secure cookie attributes (HttpOnly, Secure, SameSite).62
Access Control (Authorization): Enforce the Principle of Least Privilege: grant only the minimum permissions necessary for users, roles, and system components to perform their functions.53 Use a centralized component/library for authorization checks.56 Enforce authorization checks on every request, including server-side actions.56 Deny by default; access controls should fail securely.53 Restrict access to sensitive resources, functions, data, and configuration based on authorization.56 Implement Role-Based Access Control (RBAC) or similar models.58 Periodically re-validate authorization for long sessions.56
Cryptographic Practices: Encrypt sensitive data both at rest (storage) and in transit (network communication, e.g., using HTTPS).54 Use strong, standard, up-to-date cryptographic algorithms (e.g., AES-256, RSA, bcrypt/scrypt for hashing).57 Implement secure key management practices (generation, storage, rotation, destruction).64 Use secure random number generators for cryptographic purposes.57
Error Handling and Logging: Implement robust error handling that fails securely.53 Avoid revealing sensitive information (stack traces, system details, internal paths, credentials) in error messages presented to users or in logs.24 Log security-relevant events (logins, failures, access violations) for auditing and monitoring.56 Ensure logs themselves do not contain sensitive data.56
Dependency Management: Use components only from trusted sources.54 Keep all third-party libraries and dependencies updated to patch known vulnerabilities.54 Regularly scan dependencies for vulnerabilities using automated tools.54 Remove unused dependencies.57 (See dependency_management.md for details).


Secure Design Principles:

Secure Defaults: Configure systems and applications to be secure out-of-the-box.53 Disable unnecessary features, services, or default accounts.54
Minimize Attack Surface: Reduce the potential points of entry for attackers by limiting code complexity, removing unused features/dependencies, closing unnecessary ports, and restricting API endpoint exposure.53
Separation of Duties (SoD): Divide critical tasks and privileges among multiple users or roles to prevent unilateral misuse.53 For example, developers should not deploy code to production.53
Complete Mediation: Verify authorization for every access request to protected resources, every time.53 Do not rely on cached decisions for sensitive operations.
Fail Securely: Ensure that failures (e.g., errors, crashes, inability to access config) result in a secure state, typically by denying access or halting operations, rather than granting unintended permissions.53


Security Testing: Integrate security testing throughout the development lifecycle.54 This includes static application security testing (SAST), dynamic application security testing (DAST), dependency scanning, and potentially penetration testing.19
A crucial theme across these principles is the management of trust boundaries. Security controls like input validation, output encoding, and authorization checks are essential whenever data or control flows across a boundary between components with different levels of trust (e.g., user-to-application, application-to-database, service-to-service).53 Furthermore, security is not merely about code logic; secure configuration management (handling secrets, setting secure defaults, disabling unnecessary features) is equally critical to prevent vulnerabilities.53 Guiding an AI assistant requires embedding this holistic and proactive security mindset into its operational rules.6. Dependency Management (dependency_management.md)This module provides guidelines for managing external libraries, frameworks, and other software components relied upon by the project. Effective dependency management is crucial for security, stability, and maintainability.
Identification and Declaration: Clearly declare all project dependencies and their versions in a standard manifest file (e.g., package.json for Node.js, requirements.txt or pyproject.toml for Python).67
Package Managers: Utilize standard package managers (e.g., npm, yarn, pip, poetry, Maven, Gradle) for installing, updating, and managing dependencies.67 These tools automate processes and help resolve version conflicts.67 Use commands like npm ci or pip install -r requirements.txt --require-hashes for deterministic installations in build/CI environments, relying on lock files.69
Versioning:

Pinning: Pin dependencies to specific, immutable versions rather than using ranges, especially in production or CI environments.69
Lockfiles: Use lockfiles (e.g., package-lock.json, yarn.lock, poetry.lock, Pipfile.lock) to record the exact versions of all installed dependencies (including transitive ones).69 Commit lockfiles to version control to ensure reproducible builds across different environments and developers.69
Semantic Versioning (SemVer): Understand SemVer (MAJOR.MINOR.PATCH) principles.70 Assume dependencies follow SemVer, but be cautious, especially with pre-1.0 versions.71 Use version constraints carefully if not pinning exact versions (e.g., ^1.2.3, ~1.2.3).71
Strategy: Document the project's versioning strategy for its own releases and how it handles dependency updates.70


Security Management:

Vulnerability Scanning: Regularly scan dependencies (including transitive ones) for known vulnerabilities using automated tools (e.g., npm audit 69, pip-audit 54, Snyk 72, Dependabot 52, OWASP Dependency-Check).67 Integrate scanning into CI pipelines.69
Updating: Keep dependencies updated to the latest secure versions to patch vulnerabilities and fix bugs.54 Prioritize updates based on severity.67 Use automated tools (like Dependabot) where feasible but review updates carefully.52
Trusted Sources: Only use dependencies from reputable, trusted sources and registries.54 Be vigilant against typosquatting (similar package names) and malicious packages.58 Verify package integrity if possible.
Script Execution: Be cautious of package installation scripts. Consider disabling them using flags like npm install --ignore-scripts unless necessary and verified.69


License Compliance: Check the licenses of all dependencies (including transitive ones) for compatibility with the project's goals and legal requirements.67 Use tools to automate license checking.
Dependency Minimization: Avoid adding unnecessary dependencies.3 Regularly review and remove unused dependencies to reduce attack surface and maintenance overhead.57
Transitive Dependencies: Be aware that direct dependencies introduce their own dependencies (transitive dependencies).67 Tools and lockfiles help manage these, but vulnerability scanning must cover the entire dependency tree.
Isolation: Use environment isolation tools (e.g., Python virtual environments, Docker containers) to prevent dependency conflicts between different projects.67
Documentation: Maintain clear documentation of dependencies, their purpose, and any specific configurations or justifications for their use.67
Effective dependency management heavily relies on automation. Tools for installation, version locking, vulnerability scanning, and updates are essential for managing the complexity of modern software dependencies.52 Guiding an AI assistant should involve instructing it to utilize these tools and adhere to practices like version pinning and lockfile usage. Furthermore, security is not a one-off check but a continuous process involving regular scanning and timely updates to mitigate risks introduced through the supply chain.57 Rules should emphasize setting up and maintaining these ongoing security practices.7. General Testing Principles (testing_principles.md)This module establishes fundamental principles and practices for software testing, applicable across various methodologies and technologies.
Purpose of Testing: The primary goal of testing is to improve software quality, increase reliability, find bugs early in the development cycle, ensure the software meets requirements, and provide confidence before release.6 Working software is the primary measure of progress.78
FIRST Principles for Automated Tests: Automated tests should adhere to the FIRST principles to be effective and maintainable 79:

Fast: Tests need to run quickly to provide rapid feedback and encourage frequent execution.79 Unit tests should be particularly fast.79 Optimization techniques include parallelization and efficient data setup.80
Independent (Isolated): Tests must not depend on each other or the order of execution.79 Each test should manage its own setup and teardown, avoiding shared state or data.79 This improves reliability and simplifies debugging.80
Repeatable: Tests must produce consistent results when run multiple times in the same or different environments.79 Control the test environment and avoid non-deterministic factors (e.g., reliance on time, random data without seeding).80
Self-Validating: Tests must automatically determine whether they passed or failed without requiring manual inspection of output.79 Use clear assertions to check expected outcomes.80
Timely: Tests should be written close to the time the production code is written (ideally before or during development, as in TDD/BDD).80 They should be run frequently (e.g., on every commit/push via CI) to catch issues early when they are cheaper to fix.80


PrincipleDescriptionRationaleFastTests should execute quickly.Enables rapid feedback and frequent execution.IsolatedTests should not depend on each other or external state.Improves reliability, simplifies debugging, allows parallelization.RepeatableTests should yield consistent results across runs and environments.Ensures trustworthy results and accurate failure identification.Self-ValidatingTests should automatically determine pass/fail status.Eliminates manual checks, provides clear outcomes.TimelyTests should be written concurrently with or before production code.Catches bugs early, guides development, prevents regressions.
Test Types and Strategy (Test Pyramid/Trophy): Employ a balanced mix of test types, typically emphasizing more lower-level tests.80

Unit Tests: Test the smallest isolatable units of code (functions, methods, components) in isolation from dependencies.82 They are fast, cheap, and form the base of the testing pyramid.79
Integration Tests: Verify the interaction and communication between different units, modules, or services.82 Examples include testing interactions with databases or between microservices.82 More complex and slower than unit tests.82
Component Tests: Test a larger part of the system, potentially multiple units working together, but still isolated from external systems (often overlaps with integration testing).83
Contract Tests: Verify that interactions between services adhere to a defined contract (API schema), ensuring compatibility without needing full end-to-end deployment. (Not explicitly detailed in snippets, but relevant for microservices).
End-to-End (E2E) Tests: Simulate real user workflows across the entire integrated system, including UI, backend, databases, and external services.82 Validate complete user journeys.82 Valuable but slow, brittle, and expensive to write and maintain.82 Use sparingly for critical user flows.82
Acceptance Tests: Formal tests verifying that the system meets business requirements and user expectations.82 Often involve replicating user scenarios.82
Performance Tests: Evaluate system responsiveness, stability, and resource usage under specific load conditions.82
Smoke Tests: Quick, basic tests run after a build or deployment to check if the most critical functionalities are working.82


Test Structure: Use clear and consistent structures for tests, such as the Arrange-Act-Assert (AAA) pattern: Set up preconditions, execute the code under test, and verify the outcome.4
Test Quality: Focus on the quality and effectiveness of tests, not just the quantity or coverage percentage.84 Good tests are readable, maintainable, and test behavior rather than implementation details.84
Test Doubles (Mocks, Stubs, Fakes): Use test doubles to isolate the system under test (SUT) from its dependencies, enabling focused unit testing and improving test speed and reliability.4

Stubs: Provide fixed ("canned") responses to calls made by the SUT. Used when the test needs specific data or state from a dependency.85 Primarily for state verification.
Mocks: Objects programmed with expectations about how they should be called by the SUT. Used to verify interactions (e.g., was a specific method called with correct arguments?).85 Primarily for behavior verification.
Fakes: Provide simplified, working implementations of dependencies (e.g., an in-memory database instead of a real one).85 Allow for more complex interactions than stubs but are simpler than the real dependency.
Dummies: Objects passed around but never actually used; satisfy parameter requirements.86
Spies: Wrappers around real objects that record interactions without changing behavior.86 Useful for verifying calls without replacing the dependency entirely.


Code Coverage:

Metrics: Measure the percentage of code exercised by tests (e.g., Statement, Branch, Function/Method, Line coverage).76
Purpose: Use coverage reports as a tool to identify untested parts of the codebase, especially critical areas.76
Limitations: High coverage does not guarantee high quality or the absence of bugs.84 Coverage doesn't measure test effectiveness or quality.84 Achieving 100% coverage may not be practical or cost-effective.87
Guidance: Use coverage metrics to guide testing efforts, not as a strict target or goal.76 Prioritize testing critical and complex code paths.76


Effective software testing requires a multi-faceted approach. Relying solely on one type of test is insufficient. A strategy combining various test types, often visualized as a testing pyramid or trophy with a strong base of fast unit tests, provides better coverage and faster feedback.80 Central to unit testing is the concept of isolation, achieved through the judicious use of test doubles like mocks and stubs.4 While code coverage metrics offer insights into untested code, they should be treated as diagnostic tools rather than absolute measures of quality; the focus must remain on writing meaningful, high-quality tests that verify critical behavior.768. TDD/BDD Specific Rules (testing_tdd_bdd.md)This module outlines specific practices for Test-Driven Development (TDD) and Behavior-Driven Development (BDD), building upon general testing principles.
Test-Driven Development (TDD):

Core Cycle: TDD follows a short, iterative cycle known as Red-Green-Refactor 88:

Red: Write a small, automated test case for a specific piece of functionality before writing the implementation code. Run the test; it should fail because the code doesn't exist yet.88
Green: Write the minimum amount of production code necessary to make the failing test pass.88
Refactor: Improve the production code (and potentially the test code) for clarity, simplicity, and design quality, ensuring all tests still pass.88 Repeat the cycle for the next piece of functionality.


Principles:

Test-first approach is mandatory.88
Focus on small, incremental steps.88
Write only enough code to satisfy the current failing test (related to YAGNI).88
Frequent refactoring is integral to maintain code quality.88
Primarily focuses on unit-level testing and verifying the correctness of individual code components.89


Benefits: Leads to higher code quality, better design (modular, decoupled), fewer bugs, comprehensive test suite acting as regression safety net, forces clear thinking about requirements before coding.77
Limitations: Can be time-consuming initially, requires discipline, effectiveness depends on writing good tests, may be less suitable if requirements are very unclear.88
AI Rule Examples: "Generate a failing unit test based on the requirement before generating implementation code.", "Ensure the generated code is the minimal implementation required to pass the associated test.", "After generating passing code, suggest refactoring opportunities to improve clarity or remove duplication."


Behavior-Driven Development (BDD):

Core Focus: BDD extends TDD principles to focus on the behavior of the system from the perspective of the user or business stakeholder.77 It aims to ensure the software meets business needs and user expectations.88
Collaboration: Emphasizes collaboration between developers, testers, business analysts, and product owners to define requirements and expected behavior.77
Specification Language: Uses a structured, natural language format (often Gherkin) to describe behavior scenarios.88 The common format is Given-When-Then:

Given: Describes the initial context or preconditions.
When: Describes the event or action performed by the user/system.
Then: Describes the expected outcome or result.


Principles:

Tests are written in plain, understandable language.88
Tests are driven by business outcomes and user behavior.88
Collaboration is key to defining scenarios.88
These scenarios become executable specifications and automated regression tests.88


Benefits: Improves communication and shared understanding across teams, ensures software aligns with business goals, tests serve as living documentation, reduces ambiguity in requirements.77
Limitations: Can require more setup for automation frameworks (e.g., Cucumber, SpecFlow), may be overkill for purely technical components, effectiveness relies on active stakeholder participation.88
AI Rule Examples: "Generate BDD scenarios in Gherkin format (Given-When-Then) based on the user story.", "Translate BDD scenarios into executable test steps using the project's BDD framework.", "Ensure scenarios focus on observable user behavior and business value."


Relationship between TDD and BDD:

BDD can be seen as an evolution or extension of TDD, applying test-first principles at a higher level (behavior/feature) and emphasizing communication.88
TDD focuses on how the code is built correctly (unit level), while BDD focuses on building the right thing (behavior level).88
They are complementary: BDD scenarios can drive the definition of features, and TDD can be used to implement the individual units that fulfill those behaviors.77


While both TDD and BDD promote writing tests early, their scope and primary audience differ significantly. TDD is a developer-centric discipline focused on code design and unit correctness, using code-based tests.89 BDD is a team-oriented approach focused on shared understanding and system behavior, using natural language specifications that bridge the gap between technical and non-technical stakeholders.77 Guiding an AI requires recognizing this distinction: asking for a "TDD test" implies generating a unit test in code, while asking for a "BDD scenario" implies generating a Given-When-Then description.9. General API Design (api_design_general.md)This module covers fundamental principles applicable to designing any type of Application Programming Interface (API), whether REST, GraphQL, gRPC, or other styles.
Consistency: Maintain consistency across the entire API surface.90 This includes:

Naming Conventions: Use a consistent style for endpoints, fields, parameters, types, etc. (e.g., camelCase, snake_case, PascalCase as appropriate for the context).90
Structure: Follow consistent patterns for request and response structures.
Behavior: Ensure similar operations behave predictably across different parts of the API.
Rationale: Improves usability, reduces learning curve for consumers, makes the API feel coherent.90
AI Rule Example: "Ensure all API endpoint paths use kebab-case and request/response body fields use camelCase."


Error Handling: Design a clear and consistent error handling strategy.90

Meaningful Messages: Return specific, helpful error messages that explain what went wrong, without revealing sensitive internal details.53
Standard Codes/Types: Use standard HTTP status codes (for REST) or defined error types/codes (for GraphQL or RPC) appropriately and consistently.91
Documentation: Clearly document possible error responses for each operation, including codes and message formats.91
Rationale: Helps API consumers understand and handle failures gracefully.90
AI Rule Example: "For failed requests due to invalid input, return a 400 Bad Request status code (REST) / specific validation error type (GraphQL) with a clear message indicating the invalid field(s)."


Security: Security is non-negotiable for APIs.

Authentication: Implement robust mechanisms to verify the identity of API consumers (e.g., API keys, OAuth 2.0, OpenID Connect, JWT).58
Authorization: Ensure that authenticated consumers only have access to the resources and operations they are permitted to use.56 Apply authorization checks diligently.
Input Validation: Rigorously validate all incoming data (parameters, request bodies) to prevent injection attacks, data corruption, and unexpected behavior.56
Rate Limiting: Implement rate limiting to protect against abuse, denial-of-service attacks, and excessive resource consumption.58
Transport Security: Always use HTTPS (TLS) to encrypt data in transit.55
Information Disclosure: Avoid leaking sensitive information in responses or error messages.53
AI Rule Example: "Validate all request parameters and body fields against defined schemas. Reject requests with invalid data."


Versioning: Plan for API evolution and implement a clear versioning strategy to manage changes without breaking existing clients.70 Common strategies include URL path versioning (e.g., /v1/users), header versioning, or query parameter versioning (primarily for REST). GraphQL often relies on schema evolution with deprecation.91

AI Rule Example: "Include the API version (e.g., 'v1') in the URL path for all endpoints."


Documentation: Provide comprehensive, accurate, and easy-to-understand documentation.50

Content: Document endpoints/operations, parameters/arguments, request/response formats (including examples), authentication methods, error codes, and usage guidelines.91
Tools: Consider using standards like OpenAPI (Swagger) for REST or relying on GraphQL's introspection capabilities and tools like GraphiQL/Apollo Studio.
Rationale: Essential for API consumers to understand how to use the API correctly.91
AI Rule Example: "Generate OpenAPI documentation skeletons for all new REST endpoints, including descriptions, parameters, and example responses."


Regardless of the specific API style chosen, these general principles form the bedrock of a well-designed API. Security must be integrated from the start, covering authentication, authorization, input validation, and transport encryption.58 Equally important is the developer experience for API consumers, which is heavily influenced by consistency, clear error handling, and thorough documentation.90 Adhering to these fundamentals helps create APIs that are robust, secure, usable, and maintainable.10. REST API Design (api_design_rest.md)This module provides specific rules and best practices for designing Representational State Transfer (REST) APIs, building upon the general API principles.
Resource-Oriented Design: Structure the API around logical resources (typically nouns) that represent entities or concepts in the domain.59

URL Structure: Use clear, hierarchical, and predictable URL paths to identify resources. Use plural nouns for collections (e.g., /users, /orders). Use identifiers to specify individual resources (e.g., /users/{userId}, /orders/{orderId}) [Inferred standard practice]. Nested resources can represent relationships (e.g., /users/{userId}/orders) [Inferred standard practice].
AI Rule Example: "Use plural nouns for collection endpoints (e.g., /api/v1/products). Use path parameters for specific resource identifiers (e.g., /api/v1/products/{productId})."


Use Standard HTTP Methods (Verbs): Utilize HTTP methods semantically to perform actions on resources 59:

GET: Retrieve a resource or collection of resources. Should be safe (no side effects) and idempotent.
POST: Create a new resource within a collection, or trigger an action that doesn't fit other methods. Not typically idempotent.
PUT: Replace an existing resource entirely, or create it if it doesn't exist at a specific URL. Should be idempotent.
PATCH: Apply partial modifications to an existing resource. May or may not be idempotent depending on the operation.
DELETE: Remove a resource. Should be idempotent.
AI Rule Example: "Use POST /users to create a new user. Use GET /users/{userId} to retrieve a user. Use PUT /users/{userId} to update/replace a user. Use DELETE /users/{userId} to delete a user."


Statelessness: Each request from a client to the server must contain all the information needed to understand and process the request. The server should not store any client session state between requests. Authentication information should be sent with each request (e.g., via Authorization header).

AI Rule Example: "Ensure all API endpoints are stateless. Do not rely on server-side session state between requests."


Use Standard HTTP Status Codes: Return appropriate HTTP status codes to indicate the outcome of a request accurately. Examples:

200 OK: Successful GET, PUT, PATCH, DELETE.
201 Created: Successful POST resulting in resource creation. Include Location header pointing to the new resource.
204 No Content: Successful request with no response body (e.g., successful DELETE).
400 Bad Request: Client error (e.g., invalid syntax, validation error).
401 Unauthorized: Authentication required or failed.
403 Forbidden: Authenticated user lacks permission.
404 Not Found: Resource does not exist.
500 Internal Server Error: Unexpected server error.
AI Rule Example: "On successful resource creation via POST, return status code 201 and include a Location header with the URL of the newly created resource."


Representations (Data Formats): Typically use JSON as the format for request and response bodies due to its widespread support and ease of use in web environments [Common practice]. Set the Content-Type header appropriately (e.g., application/json). Consider supporting Accept header for content negotiation if multiple formats are needed.

AI Rule Example: "Use JSON for all request and response bodies. Set the Content-Type: application/json header for responses containing a body."


Filtering, Sorting, Pagination: For collection endpoints (GET /resources), provide mechanisms for clients to filter, sort, and paginate results using query parameters (e.g., ?status=active&sort=-createdAt&page=2&limit=20).

AI Rule Example: "Implement pagination for collection endpoints using page and limit query parameters."


Hypermedia (HATEOAS - Hypermedia as the Engine of Application State): Consider including links within responses to guide clients to related resources or possible actions. (Advanced REST principle, not always fully implemented).
Caching: Leverage standard HTTP caching mechanisms effectively, especially for GET requests.59 Use headers like ETag, Last-Modified, and Cache-Control to enable client-side or intermediary caching.59

AI Rule Example: "For GET requests on resources that change infrequently, include ETag and Last-Modified headers in the response to facilitate caching."


The core distinction of REST lies in its resource-centric approach and its deep integration with the semantics of the HTTP protocol.59 Unlike GraphQL's single endpoint, REST utilizes distinct URLs for different resources and standard HTTP verbs for actions.59 Effective REST design involves thoughtfully mapping domain entities to resources and consistently applying HTTP methods, status codes, and headers according to established conventions. This reliance on web standards facilitates interoperability and allows leveraging built-in features like browser caching.5911. GraphQL API Design (api_design_graphql.md)This module details specific rules and best practices for designing APIs using GraphQL, emphasizing its schema-driven and client-centric nature.
Schema Design (Core): The schema is the foundation of a GraphQL API.59

Naming Conventions: Use clear, descriptive, and consistent names.90 Conventionally: PascalCase for Types, Interfaces, Enums; camelCase for fields and arguments 90; UPPERCASE for Enum values.
Simplicity: Keep type definitions straightforward; avoid overly deep nesting or complexity where possible.91
Modularity: Break down large schemas into smaller, logical modules or files.91 Keep related type definitions and their resolvers together for better organization.91
Types, Interfaces, Unions: Use type for concrete object types. Use interface to define shared fields across multiple types.91 Use union to indicate a field can return one of several object types.91
Custom Scalars: Define custom scalar types for specific data formats (e.g., Date, Time, UUID, Email) to provide validation and semantic meaning beyond basic primitives (String, Int, Float, Boolean, ID).91
Nullability: Design with nullability in mind. Make fields non-nullable (Type!) only when the data is guaranteed to exist. Default to nullable types (Type) to prevent errors when data is missing.91 This applies to arguments as well.91
Pagination: Implement standardized pagination for lists/connections that can return large amounts of data (e.g., Relay Cursor Connections specification).91 Provide arguments for controlling limits and cursors/offsets.
Input Objects: Use input types for complex arguments in mutations or queries to keep argument lists clean and provide structure.
AI Rule Example: "Define custom scalar types for Date and Email validation. Use PascalCase for all type names and camelCase for all field names." 90


Queries and Mutations:

Client Specificity: Clients should query only for the fields they need.59
Variables: Always use variables for dynamic values in queries and mutations instead of embedding them directly in the query string.90 This prevents injection issues and allows query caching/reuse.90
Fragments: Use fragments to reuse common sets of fields across multiple queries or mutations, promoting DRY principles.90 Use them logically to improve readability.90
Aliases: Use aliases when fetching the same field multiple times with different arguments or to rename fields in the response for client convenience.91
Mutations Design: Design mutations to be verb-based (e.g., createUser, updatePost). Mutations should typically return the modified object(s) and potentially a success status or specific errors. Consider a single input object argument for mutations.
AI Rule Example: "When generating a mutation, define a single input object type for its arguments and ensure the return type includes the modified object."


Error Handling:

Return errors as part of the standard GraphQL response structure (in the errors array).91
Provide specific, actionable error messages and potentially error codes or custom error types for client-side handling.91
Avoid leaking sensitive internal details in production error messages.59
Document common errors.91
AI Rule Example: "Implement error handling that returns errors in the standard GraphQL errors array, including a descriptive message and a unique error code."


Performance Optimization:

N+1 Problem: Use data loading patterns (like Facebook's DataLoader) in resolvers to batch and cache requests to underlying data sources (databases, microservices), preventing the N+1 query problem.91
Server-Side Caching: Implement caching at the resolver level or use GraphQL-aware caching proxies where appropriate.91
Persisted Queries: Allow clients to send a pre-registered query ID instead of the full query string, improving performance and security.91
Query Cost Analysis: Implement mechanisms to analyze query complexity and depth before execution to prevent overly demanding queries.59
AI Rule Example: "Utilize the DataLoader pattern in resolvers to batch database lookups and prevent N+1 query issues."


Security:

Authentication: Implement standard authentication mechanisms (e.g., tokens in headers) handled before GraphQL execution begins.91
Authorization: Enforce authorization checks within resolvers at the field level to ensure users only access data they are permitted to see.59
Input Validation: Validate all query variables and input object fields rigorously.59
Rate Limiting/Query Limiting: Implement limits on query complexity, depth, and frequency to prevent abuse.59
Introspection: Disable schema introspection in production environments to avoid exposing the entire API structure.59
AI Rule Example: "Implement field-level authorization checks within resolvers to ensure data access permissions are enforced."


Schema Evolution:

Avoid breaking changes whenever possible. Add new fields instead of modifying existing ones in incompatible ways.91
Use the @deprecated directive to mark fields or enum values that are planned for removal, providing a reason and potential replacement.91 Keep deprecated fields available for a transition period.91
AI Rule Example: "When removing a field, first mark it with the @deprecated directive, providing a reason and suggesting an alternative if available."


GraphQL's power lies in its strongly-typed schema and the flexibility it grants clients.59 Effective design hinges on creating a clear, maintainable, and evolvable schema.90 While clients gain the ability to request specific data, this necessitates robust server-side implementation, particularly around performance (addressing N+1 issues with data loaders) and security (field-level authorization, query complexity limits).59 Guiding an AI requires emphasizing these schema design principles and server-side safeguards.12. Software Architecture Patterns (architecture_patterns.md)This module provides guidelines for selecting and implementing common software architectural patterns, influencing the high-level structure and organization of the application.
Layered (N-Tier) Architecture:

Concept: Organizes the application into distinct horizontal layers, each with a specific responsibility (e.g., Presentation, Business Logic, Data Access, Database).92 Communication typically occurs only between adjacent layers.92
Strengths: Promotes separation of concerns, making the system easier to understand, maintain, and test individually.93 Suitable for many traditional enterprise applications and teams needing clear structure.93
Weaknesses: Can introduce performance overhead due to requests passing through multiple layers.93 Risk of layers becoming tightly coupled, hindering independent changes.93 Can lead to monolithic structures if not carefully managed. Potential for "Spaghetti Code" or "God Objects" if boundaries are violated.94
AI Rule Examples: "Separate UI concerns (Presentation Layer) from core business rules (Business Layer) and data handling (Data Access Layer).", "Minimize direct communication between non-adjacent layers."


Microservices Architecture:

Concept: Structures an application as a collection of small, independent, and loosely coupled services, each focused on a specific business capability.92 Services communicate over a network, often via APIs or message queues.92
Strengths: Enables independent development, deployment, scaling, and technology choices for each service.92 Improves fault isolation (failure in one service doesn't necessarily bring down the whole system).95
Weaknesses: Increases operational complexity (deployment orchestration, monitoring, distributed tracing, service discovery).95 Challenges in managing distributed transactions and ensuring data consistency.96 Potential for network latency and communication overhead.96 Testing interactions can be complex.95 Requires mature DevOps practices.
Common Anti-Patterns:

Distributed Monolith: Services are deployed independently but are still tightly coupled, requiring coordinated deployments.96
Chatty Microservices: Services make excessive fine-grained calls to each other, leading to high latency.96
Shared Database: Multiple services directly accessing the same database schema, creating tight coupling.
Over-Microservicing: Breaking down services too finely, leading to excessive complexity and overhead.96


AI Rule Examples: "Design services around distinct business capabilities, ensuring high cohesion within services and loose coupling between them.", "Prefer asynchronous communication (e.g., message queues) over synchronous calls between services where possible to enhance resilience.", "Each microservice should own its own data store; avoid direct database sharing between services."


Model-View-Controller (MVC):

Concept: A pattern primarily for UI applications, separating concerns into three interconnected components 92:

Model: Manages the application's data, logic, and rules.
View: Renders the user interface based on the Model's data.
Controller: Handles user input, interacts with the Model, and selects the appropriate View to display.


Strengths: Clear separation of concerns facilitates parallel development and easier modification of UI or business logic independently. Improves testability of individual components.
Weaknesses: Can become complex in large applications. The Controller can sometimes become bloated (a "God Controller"). Defining clear boundaries can be challenging.
Frameworks: Widely used in web frameworks like Django 97, Ruby on Rails, ASP.NET MVC.
AI Rule Examples: "Place data management and business logic exclusively within the Model components.", "Views should only be responsible for presentation; avoid placing business logic in Views.", "Controllers should handle user input, orchestrate interactions between Model and View, but contain minimal application logic."


Other Patterns (Brief Mentions):

Event-Driven Architecture (EDA): Components react to events produced by other components, promoting loose coupling and scalability.92 Suitable for asynchronous workflows and real-time systems.92
Hexagonal Architecture (Ports and Adapters): Isolates the application's core logic from external concerns (UI, databases, APIs) through defined "ports" (interfaces) and "adapters" (implementations).92 Enhances testability and modularity.95
Component-Based Architecture: Builds applications by assembling independent, reusable software components.92
Command Query Responsibility Segregation (CQRS): Separates operations that read data (Queries) from operations that update data (Commands), often using different models or even data stores.92 Can improve performance and scalability for complex domains.


Choosing an architectural pattern involves significant trade-offs. Layered architectures offer simplicity and clear structure but can become monolithic.93 Microservices provide scalability and independence but introduce considerable operational complexity.95 MVC is effective for UI applications but requires careful separation of concerns.92 There is no single "best" architecture; the choice depends on project requirements, team expertise, scalability needs, and tolerance for complexity. A critical consideration is avoiding common anti-patterns associated with each architecture, such as the Distributed Monolith in microservices or God Objects/Controllers in layered/MVC systems.94 AI assistants should be guided to recommend and implement patterns appropriately based on context, while also being warned against these known pitfalls.13. General Performance Optimization (performance_general.md)This module outlines language-agnostic strategies and principles for improving application performance.
Measurement First (No Premature Optimization):

Principle: Always measure and profile the application before attempting optimization to identify actual bottlenecks.36 Do not optimize code based on assumptions.15
Rationale: Developers often guess incorrectly about performance bottlenecks. Optimizing non-critical code wastes effort and can introduce complexity or bugs.15 Focus efforts on the "critical 3%" where optimization yields significant gains.15
Tools: Use profilers (e.g., cProfile, Chrome DevTools Performance tab), benchmarking tools (e.g., timeit, Benchmark.js), and Application Performance Monitoring (APM) tools.36
AI Rule Example: "Before suggesting performance optimizations, request profiling data or identify the specific bottleneck being addressed. Avoid premature optimization."


Caching:

Concept: Store the results of expensive operations (e.g., database queries, complex calculations, API calls) temporarily so they can be retrieved quickly upon subsequent requests with the same inputs.59
Strategies:

In-Memory Caching: Store data directly in the application's memory (e.g., using dictionaries, dedicated libraries like Flask-Caching).106 Fast but limited by server memory and not shared across instances.
Distributed Caching: Use external caching systems like Redis or Memcached for shared caches accessible by multiple application instances.
Database Query Caching: Some databases or ORMs offer query caching capabilities.104
HTTP Caching: Leverage browser and proxy caching using standard HTTP headers (Cache-Control, ETag, Last-Modified) for REST APIs.59


Implementation Considerations:

Cache Keys: Choose appropriate keys to uniquely identify cached data. Consider versioning keys to handle data changes.106
Expiration (TTL): Set appropriate timeouts (Time-To-Live) based on data volatility.102
Invalidation: Implement strategies to remove or update stale data from the cache (e.g., time-based expiration, manual invalidation on data change, cache busting).106 Improper invalidation leads to serving outdated data.106
Size/Memory:* Monitor cache size to avoid excessive memory consumption.106 Consider eviction policies (e.g., LRU - Least Recently Used).


Pitfalls: Over-caching (wasting memory, stale data), under-caching (missing performance gains), complex invalidation logic.106
AI Rule Example: "For frequently accessed, computationally expensive functions with deterministic outputs, implement caching using with an appropriate timeout (e.g., 60 seconds)." 106


Database Optimization:

Query Efficiency: Write efficient database queries. Avoid fetching unnecessary data (select only needed columns/fields).108 Minimize the number of queries (e.g., avoid N+1 problems by using joins or batching).104
Indexing: Create database indexes on columns frequently used in WHERE clauses, JOIN conditions, and ORDER BY clauses to speed up data retrieval.104
Connection Pooling: Reuse database connections instead of establishing a new one for each request to reduce overhead.109
AI Rule Example: "Analyze database queries for potential N+1 problems. Suggest using select_related or prefetch_related (Django) or equivalent eager loading techniques." 108


Asynchronous Processing: Utilize non-blocking I/O and asynchronous programming models (e.g., async/await, Promises, callbacks, event loops) where appropriate, especially for I/O-bound operations (network requests, file system access, database queries).109 This prevents blocking the main execution thread and allows the application to handle more concurrent requests.109 (See language-specific modules like javascript_nodejs.md).
Resource Management:

Memory: Optimize memory usage by choosing efficient data structures, avoiding loading large datasets entirely into memory (use streaming or pagination), and preventing memory leaks (ensure resources and references are properly released).36
Connections: Close database connections, file handles, and network sockets promptly after use.56
AI Rule Example: "When processing large files, use streaming APIs instead of reading the entire file into memory."


Algorithm and Data Structure Choice: Select algorithms and data structures that are appropriate for the task and scale well with the expected input size.36 A suboptimal algorithm (e.g., O(n^2) where O(n log n) exists) can be a major bottleneck.
Payload and Asset Optimization: Minimize the amount of data transferred over the network. Compress HTTP responses (e.g., using gzip).109 Optimize images (use appropriate formats like WebP, compress).112 Minify CSS and JavaScript files. Fetch only the data needed by the client.59
The cardinal rule of performance optimization is to measure first.15 Without identifying the true bottlenecks through profiling, optimization efforts are often wasted or even detrimental. Caching is a widely applicable and powerful technique, but its implementation requires careful consideration of key management, expiration, and invalidation to avoid introducing subtle bugs or inconsistencies.106 Optimizing database interactions, leveraging asynchronous patterns, managing resources efficiently, and choosing appropriate algorithms are other key pillars of building performant applications.14. Python General Rules (python_general.md)This module defines coding standards and idioms specific to the Python language, largely based on PEP 8 and community best practices.
PEP 8 Adherence: Code must follow PEP 8, the official style guide for Python.29

Rationale: Ensures consistency, readability, and maintainability across Python projects and developers.29
AI Rule: "Ensure all generated Python code strictly adheres to PEP 8 guidelines."


Naming Conventions:

Variables, Functions, Methods, Modules: Use snake_case (lowercase with underscores).18
Classes: Use PascalCase (also known as CapWords).10
Constants: Use UPPERCASE_WITH_UNDERSCORES.10
Protected/Private: Use a single leading underscore (_protected) for internal use (convention, not enforced). Use double leading underscore (__private) for name mangling (use sparingly).
Meaningful Names: Names should be descriptive and reveal intent.10 Avoid single letters (except loop counters, exception variables).29 Use pronounceable names.20 Avoid ambiguous abbreviations.20 Be consistent with vocabulary.20
AI Rule: "Use snake_case for functions and variables, PascalCase for classes."


Code Layout:

Indentation: Use 4 spaces per indentation level. Never use tabs or mix tabs and spaces.20
Line Length: Limit lines to a maximum of 79 characters for code and 72 for docstrings/comments.20 Modern formatters like Black often default to 88 characters, which is also acceptable if used consistently.29 Use parentheses for implicit line continuation.29
Blank Lines: Two blank lines between top-level functions and classes.20 One blank line between methods within a class.20 Use blank lines sparingly within functions to separate logical steps.30
Whitespace: Spaces around operators (=, +=, ==, <, *, etc.).20 No extra spaces inside parentheses, brackets, or braces.20 One space after commas and colons.38
Imports: Place imports at the top of the file, after module docstrings but before global constants/variables. Group imports: 1. Standard library, 2. Third-party, 3. Local application/library imports. Separate groups with a blank line.29 Avoid wildcard imports (from module import *). Prefer importing modules (import os) or specific names (from collections import deque) over importing entire modules into the current namespace if it causes naming conflicts.
AI Rule: "Format code using 4 spaces for indentation and limit lines to 88 characters."


Idiomatic Python ("Pythonic" Code): Write code that leverages Python's features naturally and readably.25

Iteration: Use for item in sequence: directly. Use enumerate() for index and item.25 Use zip() to iterate over multiple sequences simultaneously.
Comprehensions: Use list, dictionary, and set comprehensions for creating collections concisely and often more efficiently than explicit loops with .append().25 Example: squares = [x**2 for x in range(10)].25 Avoid unnecessary comprehensions if a built-in function works directly on an iterator (e.g., sum(i for i in...), any(...)).114
Generators: Use generator functions (yield) or generator expressions ((x for x in...)) for lazy evaluation, especially with large sequences or streams, to save memory.25
Context Managers (with): Use the with statement for resources that need cleanup (files, locks, network connections) to ensure resources are released properly, even if errors occur.114 Example: with open('file.txt') as f: data = f.read().114
Dictionary Handling: Use .get(key, default) to access dictionary keys safely with a default value.25 Use .items() to iterate over key-value pairs.114
String Formatting: Prefer f-strings (Python 3.6+) for formatting strings: f"Hello, {name}!".
Boolean Comparisons: Use if condition: or if not condition:. Avoid explicit comparison to True or False (if condition == True:).38 Use is and is not for comparing with singletons like None (if var is None:).
Type Checking: Prefer "duck typing" (checking for behavior/methods) over explicit type checking with isinstance(). Use type hints (PEP 484) for static analysis and clarity, but don't rely on them for runtime enforcement unless using specific tools.
Default Arguments: Avoid using mutable default arguments (like lists or dictionaries) in function definitions, as they persist across calls. Use None as a default and create the mutable object inside the function if needed. (Common pitfall).
Literals: Prefer literal syntax for creating empty lists (``), dicts ({}), and tuples (()) over calling the type constructors (list(), dict(), tuple()).114
AI Rule: "Use list comprehensions for concise list creation. Use the with statement for file handling."


Functions and Methods: Follow the Single Responsibility Principle; keep them short and focused on one task.10 Minimize the number of arguments.20 Avoid boolean flag arguments; consider splitting the function.20 Return consistent object types; raise exceptions for error conditions rather than returning None or a different type if possible.114
Error Handling: Use try...except blocks to handle potential exceptions gracefully.36 Catch specific exceptions rather than a bare except:. Define custom exception classes for application-specific errors.
Comments and Docstrings: Use docstrings (following PEP 257) for all public modules, functions, classes, and methods.10 Use # comments for inline explanations of non-obvious code.30 (See documentation_standards.md).
Tooling: Employ linters (Pylint 27, Flake8 27, Ruff 41) and auto-formatters (Black, YAPF) 36 to enforce style and catch potential issues automatically.27 Integrate these tools into the development workflow (IDE plugins, pre-commit hooks, CI pipelines).41

AI Rule: "Ensure generated code passes checks from and is formatted according to."


The foundation of good Python code rests on adhering to PEP 8, which promotes readability and consistency vital for collaboration.29 Automated linters and formatters are crucial for enforcing these standards effectively across a team or project.27 Beyond basic style, writing "Pythonic" code involves leveraging the language's specific features like comprehensions, generators, and context managers, which often lead to more concise, readable, and sometimes more efficient solutions than approaches borrowed from other languages.25 Common anti-patterns often arise from neglecting these idioms or basic principles, such as improper file handling or using magic numbers.20 AI assistants should be guided to produce code that is not only correct but also adheres to these Pythonic conventions and avoids common pitfalls.15. Python Performance (python_performance.md)This module provides guidelines specifically for optimizing the performance of Python code.
Measurement First: Always profile the code before optimizing to identify the actual bottlenecks.36 Use tools like cProfile 100, timeit 100, or external APM tools.100 Avoid premature optimization.15

AI Rule: "Identify performance bottlenecks using profiling data before applying optimizations."


Use Efficient Data Structures:

Choose the right built-in data structure for the task: Use sets (set) for fast membership testing (checking if an item is in a collection). Use dictionaries (dict) for fast key-based lookups. Use tuples (tuple) for immutable sequences (can be slightly faster and use less memory than lists for fixed collections). Use lists (list) for ordered sequences that require modification.36
For numerical computations on large datasets, use NumPy arrays, which are implemented in C and provide vectorized operations that are significantly faster than Python loops.36
AI Rule: "For large numerical datasets or matrix operations, use NumPy arrays instead of standard Python lists."


Optimize Loops:

Minimize work done inside loops. Move calculations or lookups outside the loop if they don't change with each iteration.116
Prefer list comprehensions or generator expressions over manual for loops with .append() for creating lists, as they are often faster and more concise.36
Use built-in functions like map(), filter(), sum() that operate on iterables, as they are often implemented in C.116 Use any() and all() for boolean checks, which support short-circuiting.114
AI Rule: "Replace for loops that build lists using .append() with equivalent list comprehensions where appropriate."


Function Calls and Scope:

Function calls have overhead. Avoid unnecessary calls within tight loops.
Local variable access is faster than global variable access.36 If a global variable is used repeatedly in a loop, assign it to a local variable before the loop.
Attribute lookups (object.attribute) and method lookups (object.method) also have overhead. If a method is called repeatedly in a loop, assign it to a local variable before the loop: local_method = object.method then call local_method() inside.116
Avoid recursion for deep computations if an iterative solution is possible and clearer, as recursion can have higher overhead and hit recursion depth limits.36
AI Rule: "Cache method lookups in local variables before using them inside performance-critical loops." 116


String Operations:

For building large strings by concatenating many smaller strings (especially in loops), use "".join(list_of_strings) instead of repeated use of the + operator. join is generally more efficient.100
Use f-strings (Python 3.6+) for general string formatting, as they are typically the fastest option.
AI Rule: "Use "".join() to concatenate a large number of strings instead of using the + operator in a loop."


Leverage Optimized Libraries:

Use built-in functions and modules whenever possible, as many are implemented in C for speed.100
For scientific and numerical computing, use libraries like NumPy and SciPy.36
For performance-critical sections that cannot be optimized sufficiently in Python, consider using Cython to compile Python-like code to C extensions 36, or writing C extensions directly.
Use faster alternatives for standard library modules if available and appropriate (e.g., cPickle over pickle in older Python, though pickle is often C-accelerated now; third-party libraries like orjson for JSON)..100
AI Rule: "For computationally intensive numerical algorithms, utilize NumPy/SciPy functions instead of pure Python implementations."


Memory Management:

Use generators (yield) and generator expressions ((...)) instead of lists or list comprehensions when dealing with large sequences where all elements are not needed in memory simultaneously.36 This implements lazy evaluation.
For large datasets, consider techniques like processing data in chunks, sampling, or using libraries designed for out-of-core computation (like Dask or Vaex).36
Be mindful of creating large intermediate data structures.
AI Rule: "Use generator expressions instead of list comprehensions when iterating over large sequences if the full list is not required in memory."


Concurrency and Parallelism: For I/O-bound tasks (waiting for network, disk), use asyncio or threading. For CPU-bound tasks (heavy computation) on multi-core machines, use the multiprocessing module to bypass the Global Interpreter Lock (GIL).36
Interpreter: Consider using PyPy, an alternative Python implementation with a Just-In-Time (JIT) compiler, which can significantly speed up long-running, CPU-bound pure Python code.100
Python performance optimization often involves choosing the right tools and techniques provided by the language and its ecosystem. Leveraging C-optimized built-in functions, standard libraries like NumPy, and appropriate data structures is frequently more effective than micro-optimizing pure Python loop constructs.36 Understanding variable lookup costs (local vs. global, attribute access) can also guide optimizations in critical loops.36 As always, profiling is essential to ensure efforts are directed at actual bottlenecks.3616. Python Security (python_security.md)This module focuses on security best practices specifically for Python application development, referencing general security principles like those from OWASP.
Input Validation and Sanitization:

Principle: Never trust user input or data from external sources. Always validate and sanitize it before use.54
Risks: Failure to validate can lead to injection attacks (SQL Injection, Command Injection, Cross-Site Scripting - XSS), denial of service, and other vulnerabilities.54
Techniques: Use validation libraries (e.g., Pydantic, Marshmallow, Cerberus) to check data types, formats, ranges, and lengths. Sanitize input to remove or encode potentially harmful characters, especially before using it in database queries, OS commands, or HTML output. Avoid dangerous functions like eval() or exec() with untrusted input.57
AI Rule: "Validate all user-provided input against a defined schema using a library like Pydantic before processing." 58


Preventing Injection Attacks:

SQL Injection: Use Object-Relational Mappers (ORMs) like Django ORM or SQLAlchemy, which typically handle parameterization automatically. If using raw SQL, always use parameterized queries (pass values separately from the SQL string) rather than string formatting/concatenation.54
Command Injection: Avoid calling shell commands directly using modules like os.system or subprocess.run with shell=True and untrusted input. If necessary, carefully sanitize input and pass arguments as a list, not a single string.56 Use built-in Python functions where possible instead of external commands.56
XSS: When generating HTML (e.g., in web frameworks), ensure user input is properly escaped/encoded before rendering. Use framework features (like Jinja2 autoescaping in Flask/Django) or libraries like bleach or DOMPurify (if running JS on server or validating HTML snippets).54 (See framework-specific rules).
AI Rule: "Use parameterized queries or ORM methods to interact with the database. Never construct SQL queries using string formatting with user input." 56


Dependency Security:

Management: Use tools like pip-audit 54 or external services (Snyk, Dependabot) to scan dependencies for known vulnerabilities.54
Updates: Keep dependencies (including Python itself) regularly updated to patch security flaws.54
Sources: Install packages only from trusted sources (e.g., PyPI, trusted internal repositories). Be wary of typosquatting.54
AI Rule: "Ensure requirements.txt or pyproject.toml pins dependencies to specific versions. Include a step in CI to run pip-audit."


Secure Error Handling:

Use try...except blocks to handle potential errors gracefully.57
Avoid exposing sensitive information (stack traces, configuration details, internal paths) in error messages shown to users or logged insecurely.54 Configure logging appropriately for production environments.
AI Rule: "Implement generic error messages for users in production environments. Log detailed error information, excluding sensitive data, securely on the server-side."


Data Security:

Secrets Management: Do not hardcode secrets (API keys, passwords, encryption keys) in source code.54 Use environment variables, secrets management systems (like HashiCorp Vault, AWS Secrets Manager), or secure configuration files.54
Cryptography: Use standard, strong cryptographic libraries like hashlib (for hashing) and cryptography (for encryption).57 Use secure hashing algorithms like SHA-256 or higher for integrity checks, and bcrypt or scrypt for password hashing.57 Use strong encryption algorithms like AES for data at rest/in transit.54 Follow secure key management practices.54 Use the secrets module for generating cryptographically secure random numbers/tokens.57
AI Rule: "Retrieve sensitive credentials (e.g., database passwords, API keys) from environment variables or a secrets management service. Do not hardcode them." 54


Serialization Security:

Be extremely cautious when deserializing data from untrusted sources, especially using formats like pickle, which can execute arbitrary code.54 Prefer safer serialization formats like JSON if possible.
If using pickle is unavoidable, only deserialize data from trusted sources and consider using signing or other integrity checks. Validate data after deserialization but before use.
AI Rule: "Avoid using pickle to deserialize data from untrusted sources. Prefer JSON or other safer formats. If pickle must be used, ensure the data source is trusted and validated."


Access Control:

Implement the Principle of Least Privilege: Ensure Python processes run with the minimum necessary operating system permissions.57 Limit file system access and network permissions.
Within the application, enforce authorization checks to ensure users can only access data and perform actions they are permitted to.54
AI Rule: "When accessing files or external resources, ensure the application runs with the minimum required permissions."


Code Quality and Review: Regularly review code for security flaws.57 Use static analysis security testing (SAST) tools specifically designed for Python to identify potential vulnerabilities early.54
Python's flexibility requires developers to be diligent about security. Input validation remains a cornerstone defense against many common attacks like injection and XSS.54 Managing dependencies securely is also critical, as vulnerabilities in third-party libraries are a frequent source of compromise.54 Developers must also be wary of Python-specific risks, particularly the dangers associated with deserializing untrusted data using formats like pickle.54 Adhering to the principle of least privilege and securely managing secrets are further essential practices.17. Flask Framework Rules (python_flask.md)This module provides rules tailored for developing web applications using the Flask microframework, incorporating security and performance best practices.
Project Structure:

Application Factory Pattern: Use the application factory pattern (def create_app():) to initialize the Flask app.117 This facilitates testing, configuration management, and creating multiple app instances.117
Blueprints: Organize larger applications into modular Blueprints.117 Register blueprints within the application factory.117
Separation: Separate the application creation (app.py or factory) from the server execution logic (e.g., run.py or WSGI entry point).120
AI Rule: "Structure the application using the factory pattern (create_app) and organize distinct functional areas into Blueprints." 118


Configuration:

Load configuration early in the factory function.117
Use app.config.from_pyfile() for file-based configuration or app.config.from_envvar() to load config based on an environment variable pointing to a file.117 Use app.config.from_prefixed_env() (Flask 2.0+) to load directly from environment variables.117
Maintain separate configuration files/settings for development, testing, and production environments.117
Store sensitive configuration (secrets, API keys, database URIs) outside of version control, preferably using environment variables or a secrets management system.117 Access via os.environ.get() or app.config.from_prefixed_env().
AI Rule: "Load application configuration using app.config.from_pyfile() or app.config.from_prefixed_env(). Store secrets in environment variables, not directly in config files." 117


Context Management:

Understand the difference between Application Context and Request Context.121
Use current_app proxy to access the application instance within request handlers or CLI commands, instead of importing the app object directly.119
Use g object to store request-scoped data (e.g., database connections, user information).121 Ensure resources stored on g are cleaned up using @app.teardown_appcontext handlers.121
Use with app.app_context(): when needing access to current_app or g outside of a request or CLI command (e.g., in setup scripts, background tasks, tests).119
AI Rule: "Use g to store request-specific resources like database connections, and register a teardown function using @app.teardown_appcontext to close them." 121


Templating (Jinja2):

Leverage Jinja2's automatic HTML escaping by default to prevent XSS.62
Avoid using the |safe filter or Markup() unless the content is explicitly trusted and sanitized.62
Always quote HTML attributes when embedding Jinja expressions to prevent attribute injection XSS: <input value="{{ user_input }}">.62
Use template inheritance ({% extends 'base.html' %}, {% block content %}) for DRY templates.122
AI Rule: "Rely on Jinja2's default autoescaping for rendering user-provided data. Only use |safe on pre-sanitized, trusted HTML." 62


Security:

CSRF Protection: Use the Flask-WTF extension for easy integration with forms, which handles token generation and validation automatically.65 Alternatively, use Flask-SeaSurf.65 Ensure the SECRET_KEY is strong and kept secret, as it's used for signing CSRF tokens.
XSS Protection: Primarily handled by Jinja2 autoescaping (see Templating). Sanitize any input rendered unsafely. Implement a Content Security Policy (CSP), possibly using Flask-Talisman.65
Session Cookies: Set SESSION_COOKIE_SECURE=True, SESSION_COOKIE_HTTPONLY=True, and SESSION_COOKIE_SAMESITE='Lax' (or 'Strict') in the app config for enhanced session security.62 Requires HTTPS for Secure flag.
Input Validation: Validate all incoming request data (query parameters, form data, JSON bodies) using libraries like WTForms 122, Marshmallow, or Pydantic before processing.
Resource Limits: Set MAX_CONTENT_LENGTH, MAX_FORM_MEMORY_SIZE, and MAX_FORM_PARTS in the app config to mitigate potential Denial-of-Service (DoS) attacks via large requests.62
HTTPS: Deploy the application behind a secure web server (like Nginx or Apache) configured for HTTPS. If Flask needs to be aware of HTTPS (e.g., for URL generation or secure cookies when behind a proxy), configure werkzeug.middleware.proxy_fix or ensure the proxy sets appropriate headers (X-Forwarded-Proto). Use Flask-Talisman for HSTS enforcement.65
Security Headers: Use Flask-Talisman or manually set headers like X-Content-Type-Options: nosniff, X-Frame-Options: DENY (or SAMEORIGIN), and CSP.62
AI Rule: "Enable CSRF protection using Flask-WTF. Set SESSION_COOKIE_SECURE, SESSION_COOKIE_HTTPONLY, and SESSION_COOKIE_SAMESITE='Lax' in production configuration." 62


Performance:

Caching: Use the Flask-Caching extension to cache expensive view function results or database queries.102 Decorate views with @cache.cached(timeout=...). Choose appropriate timeouts and consider cache invalidation strategies.106 Monitor cache performance and memory usage.106
Database Queries: Optimize database interactions (see performance_general.md). Use ORMs like Flask-SQLAlchemy efficiently.122
Middleware: Implement custom middleware using @app.before_request, @app.after_request, or @app.teardown_request for cross-cutting concerns like request logging or timing.102
Asynchronous Views: Flask supports async views (using async def) when running with an ASGI server (like Hypercorn or Uvicorn), which can improve performance for I/O-bound tasks.
AI Rule: "Apply caching using @cache.cached() from Flask-Caching to views performing expensive, repeatable operations. Set a reasonable timeout." 102


Error Handling: Use @app.errorhandler(ErrorCodeOrException) decorators to register custom handlers for specific HTTP status codes or exceptions. Log errors appropriately.
Common Patterns: Use flash() for displaying one-time messages to users.122 Handle file uploads securely (validate filenames, types, sizes; store safely).122 Offload long-running tasks to background workers using libraries like Celery.122
Flask's microframework nature means that structure and many essential features rely on established patterns and extensions. The application factory pattern combined with Blueprints is the standard approach for building maintainable and testable Flask applications beyond the simplest examples.117 Understanding Flask's context locals (current_app, g) is fundamental for accessing application state and managing request resources correctly.121 Security and performance often depend on integrating and configuring extensions like Flask-WTF, Flask-Caching, and Flask-Talisman.65 AI guidance should reflect this reliance on community patterns and extensions.18. Django Framework Rules (python_django.md)This module provides rules specific to the Django web framework, emphasizing its conventions, built-in features, and performance considerations.
Design Philosophy Adherence: Follow Django's core philosophies: Loose Coupling, Less Code (DRY), Quick Development, Explicit is Better than Implicit, Consistency.123 Leverage Django's built-in components (ORM, Admin, Auth, Forms, Templates).63

AI Rule: "Utilize Django's built-in features (ORM, Forms, Auth, Admin, Generic Views) where appropriate, following framework conventions to minimize boilerplate code." 123


Project and App Structure: Use django-admin startproject and python manage.py startapp to create standard project and app layouts.97 Keep apps focused on a single area of functionality.
Models (models.py):

Define data models clearly using Django's model fields.97
Use ForeignKey, ManyToManyField, OneToOneField explicitly for relationships.
Add db_index=True to fields frequently used in filter(), exclude(), order_by() clauses for performance.104 Define composite indexes in Meta.indexes if needed.
Avoid null=True on string-based fields (CharField, TextField). Use blank=True and an empty string default='' instead if the field is optional at the form level but required at the database level.108
AI Rule: "Add db_index=True to ForeignKey fields and other model fields commonly used for filtering or ordering querysets." 107


Views (views.py):

Implement request handling logic in views.97
Prefer Django's Class-Based Views (CBVs), especially Generic Views (ListView, DetailView, CreateView, UpdateView, DeleteView), for common data display and manipulation patterns.124 Subclass generic views to customize behavior.124
Use function-based views for simpler or highly custom logic.97
Keep views focused; delegate complex business logic to model methods, managers, or separate service layers.
Return HttpResponse objects, typically using shortcuts like render() (for templates) or redirect().97 Use get_object_or_404() to handle missing objects gracefully.97
AI Rule: "For standard list/detail/create/update/delete operations on a model, use Django's generic Class-Based Views (e.g., ListView, DetailView)." 124


Templates:

Use the Django Template Language (DTL) for presentation logic only.123 Avoid complex logic in templates.123
Utilize template inheritance ({% extends %}, {% block %}) to keep templates DRY.123
Leverage built-in template tags and filters. Create custom tags/filters for reusable presentation logic.123
Rely on Django's default autoescaping to prevent XSS.55 Avoid using {% autoescape off %} or the |safe filter unless the data is explicitly trusted and sanitized.63
Include {% csrf_token %} inside all <form> tags targeting internal URLs via POST.55
Use the json_script template tag to safely pass data to JavaScript.63
Place templates in app-specific templates/<app_name>/ directories for namespacing.97
AI Rule: "Always include {% csrf_token %} within POST forms. Rely on autoescaping; avoid |safe unless the variable is guaranteed to be secure." 63


URLs (urls.py):

Define URL patterns using path() (preferred) or re_path().97
Use include() to delegate URL patterns to application-specific urls.py files.
Use URL namespaces to avoid name collisions between apps.97
Use the {% url %} template tag or the reverse() function in Python code instead of hardcoding URL paths.97
AI Rule: "Use named URL patterns and reference them using {% url 'namespace:name' %} in templates or reverse('namespace:name') in views." 97


Forms (forms.py):

Use Django's Forms API (forms.Form, forms.ModelForm) to handle user input, validation, and cleaning.
ModelForm automatically builds a form based on a Django model.
Forms automatically handle CSRF protection when rendered correctly with {% csrf_token %}.


Admin Interface (admin.py):

Register models with the admin site to enable data management.104
Customize ModelAdmin classes to improve usability and performance:

Use list_display to show relevant fields in the list view.
Use list_filter for filtering options.
Use search_fields for search functionality.
Use list_select_related (boolean or tuple) or list_prefetch_related (tuple) to optimize queries in the list view.104
Use raw_id_fields for foreign keys with many related objects.


AI Rule: "In ModelAdmin for models with ForeignKey relationships displayed in list_display, set list_select_related = True or specify fields to optimize performance." 104


ORM Performance Optimization:

N+1 Queries: Aggressively use select_related() for forward ForeignKey/OneToOne relationships and prefetch_related() for ManyToMany or reverse ForeignKey relationships accessed in loops or templates.104
Field Selection: Use only() to fetch only specific model fields when the full object isn't needed. Use defer() to exclude specific, large fields unless accessed.108 Use values() or values_list() to retrieve data as dictionaries or tuples, bypassing model instance creation overhead, especially for large datasets or when only a few fields are needed.108
Counting/Existence: Use .count() for counting objects instead of len(queryset).108 Use .exists() to check if any objects match a query instead of if queryset: or .count() > 0.108
Indexing: Ensure database indexes exist for fields used in filtering/ordering (db_index=True, Meta.indexes).104
Bulk Operations: Use bulk_create(), bulk_update(), bulk_delete() for creating/updating/deleting multiple objects efficiently.108
QuerySet Evaluation: Understand that QuerySets are lazy. They are evaluated only when iterated over, sliced (with step), pickled, or when repr(), len(), list(), or bool() is called. Django caches the results after evaluation.108 Avoid unnecessary re-evaluation of the same QuerySet.108
Debugging: Use django-debug-toolbar to inspect SQL queries generated by the ORM during development.104
AI Rule: "When iterating over a QuerySet and accessing related objects via ForeignKey, use select_related('foreign_key_field'). For ManyToMany or reverse ForeignKey access, use prefetch_related('related_field_name')." 107


Security:

Core Settings: Never run with DEBUG = True in production.63 Keep SECRET_KEY secret and secure (use environment variables).63 Configure ALLOWED_HOSTS correctly for production.
Authentication/Authorization: Use django.contrib.auth.63 Implement password validation rules (AUTH_PASSWORD_VALIDATORS).63 Use permissions framework for authorization.
CSRF: Ensure CsrfViewMiddleware is enabled (default) and use {% csrf_token %} in POST forms.55 Avoid csrf_exempt.55 Use `CSRF


